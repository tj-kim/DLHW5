{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Written Exercise 5.\n",
    "\n",
    "Another assumption we made in the homework is that the data used for training shadow models\n",
    "is independent of the data used to train the attacked model f (x). Investigate attack success as a function\n",
    "of the intersection between shadow data and training data. Your should include a graphic that presents a\n",
    "measure of shared data on one axis and the resulting attacker success on the other. Investigate at least 3\n",
    "levels of overlap outside of no overlap.\n",
    "\n",
    "The following steps will be taken:\n",
    "\n",
    "1. Build a function that takes in shadow data, training data and the overlap proportion and returns training and shadow data with a certain amount of overlap.\n",
    "\n",
    "2. Loop through different overlap values [0, 0.5, 0.9, 1] and train models at 30 epochs, batch size 2048.\n",
    "\n",
    "3. Make plots of attack success rate vs. overlap level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hw5_part1_utils\n",
    "\n",
    "from typing import Tuple\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hw5_part1 import synthesize_attack_data, build_attack_models, evaluate_membership\n",
    "\n",
    "data = hw5_part1_utils.CIFARData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Build Function that overlaps training and shadow data\n",
    "\n",
    "Because shadow data has 20k samples, and train data has 10k samples, I will simply take 10k samples from shadow data to train the shadow model so that there is controlled overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_datasets(train_data, train_label, shadow_data, shadow_label, proportion):\n",
    "    \"\"\"\n",
    "    Returns 2 datasets, one for training and other for shadow training \n",
    "    with proportion overlap between the two.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_length = min([train_data.shape[0], shadow_data.shape[0]])\n",
    "    num_shared = int(np.floor(data_length*proportion))\n",
    "    \n",
    "    shared_data = shadow_data[data_length:data_length + num_shared]\n",
    "    shared_data_labels = shadow_label[data_length:data_length+num_shared]\n",
    "    \n",
    "    new_train_data = np.append(train_data[0:data_length-num_shared], shared_data, axis=0)\n",
    "    new_train_label = np.append(train_label[0:data_length-num_shared], shared_data_labels, axis=0)\n",
    "    \n",
    "    new_shadow_data = np.append(shadow_data[0:data_length-num_shared], shared_data, axis=0)\n",
    "    new_shadow_label = np.append(shadow_label[0:data_length-num_shared], shared_data_labels, axis=0)\n",
    "    \n",
    "    return new_train_data, new_train_label, new_shadow_data, new_shadow_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Loop through different proportions to train model, shadow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tkim/miniconda3/envs/fsdl/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tkim/miniconda3/envs/fsdl/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tkim/miniconda3/envs/fsdl/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/tkim/Fair_DL/hw5/hw5_part1_utils.py:134: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "attack model no. 0\n",
      "WARNING:tensorflow:From /home/tkim/miniconda3/envs/fsdl/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 3936 samples\n",
      "Epoch 1/30\n",
      "3936/3936 [==============================] - 0s 90us/sample - loss: 0.6921 - acc: 0.5112\n",
      "Epoch 2/30\n",
      "3936/3936 [==============================] - 0s 8us/sample - loss: 0.6861 - acc: 0.5518\n",
      "Epoch 3/30\n",
      "3936/3936 [==============================] - 0s 5us/sample - loss: 0.6790 - acc: 0.5838\n",
      "Epoch 4/30\n",
      "3936/3936 [==============================] - 0s 9us/sample - loss: 0.6733 - acc: 0.6070\n",
      "Epoch 5/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6663 - acc: 0.6179\n",
      "Epoch 6/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6625 - acc: 0.6199\n",
      "Epoch 7/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6549 - acc: 0.6326\n",
      "Epoch 8/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6481 - acc: 0.6410\n",
      "Epoch 9/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6527 - acc: 0.6303\n",
      "Epoch 10/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6452 - acc: 0.6341\n",
      "Epoch 11/30\n",
      "3936/3936 [==============================] - 0s 11us/sample - loss: 0.6421 - acc: 0.6402\n",
      "Epoch 12/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6441 - acc: 0.6319\n",
      "Epoch 13/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6418 - acc: 0.6405\n",
      "Epoch 14/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6443 - acc: 0.6263\n",
      "Epoch 15/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6355 - acc: 0.6428\n",
      "Epoch 16/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6390 - acc: 0.6326\n",
      "Epoch 17/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6353 - acc: 0.6392\n",
      "Epoch 18/30\n",
      "3936/3936 [==============================] - 0s 8us/sample - loss: 0.6312 - acc: 0.6420\n",
      "Epoch 19/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6362 - acc: 0.6316\n",
      "Epoch 20/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6357 - acc: 0.6347\n",
      "Epoch 21/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6348 - acc: 0.6344\n",
      "Epoch 22/30\n",
      "3936/3936 [==============================] - 0s 5us/sample - loss: 0.6285 - acc: 0.6400\n",
      "Epoch 23/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6338 - acc: 0.6288\n",
      "Epoch 24/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6320 - acc: 0.6255\n",
      "Epoch 25/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6295 - acc: 0.6402\n",
      "Epoch 26/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6288 - acc: 0.6413\n",
      "Epoch 27/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6307 - acc: 0.6326\n",
      "Epoch 28/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6316 - acc: 0.6303\n",
      "Epoch 29/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6283 - acc: 0.6456\n",
      "Epoch 30/30\n",
      "3936/3936 [==============================] - 0s 13us/sample - loss: 0.6255 - acc: 0.6321\n",
      "attack model no. 1\n",
      "Train on 4028 samples\n",
      "Epoch 1/30\n",
      "4028/4028 [==============================] - 0s 88us/sample - loss: 0.6840 - acc: 0.5139\n",
      "Epoch 2/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.6688 - acc: 0.5802\n",
      "Epoch 3/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.6575 - acc: 0.6358\n",
      "Epoch 4/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.6466 - acc: 0.6696\n",
      "Epoch 5/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6314 - acc: 0.6907\n",
      "Epoch 6/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.6283 - acc: 0.6827\n",
      "Epoch 7/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.6213 - acc: 0.6783\n",
      "Epoch 8/30\n",
      "4028/4028 [==============================] - 0s 8us/sample - loss: 0.6137 - acc: 0.6795\n",
      "Epoch 9/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5996 - acc: 0.6919\n",
      "Epoch 10/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5979 - acc: 0.6919\n",
      "Epoch 11/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5913 - acc: 0.6961\n",
      "Epoch 12/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5958 - acc: 0.6820\n",
      "Epoch 13/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5927 - acc: 0.6909\n",
      "Epoch 14/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5782 - acc: 0.6964\n",
      "Epoch 15/30\n",
      "4028/4028 [==============================] - 0s 8us/sample - loss: 0.5832 - acc: 0.6929\n",
      "Epoch 16/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5867 - acc: 0.6783\n",
      "Epoch 17/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5881 - acc: 0.6817\n",
      "Epoch 18/30\n",
      "4028/4028 [==============================] - 0s 8us/sample - loss: 0.5823 - acc: 0.6802\n",
      "Epoch 19/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5767 - acc: 0.6964\n",
      "Epoch 20/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5693 - acc: 0.6951\n",
      "Epoch 21/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5702 - acc: 0.6971\n",
      "Epoch 22/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5799 - acc: 0.6899\n",
      "Epoch 23/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5788 - acc: 0.6795\n",
      "Epoch 24/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5717 - acc: 0.6931\n",
      "Epoch 25/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5690 - acc: 0.6939\n",
      "Epoch 26/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5727 - acc: 0.6999\n",
      "Epoch 27/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5648 - acc: 0.7033\n",
      "Epoch 28/30\n",
      "4028/4028 [==============================] - 0s 6us/sample - loss: 0.5658 - acc: 0.6922\n",
      "Epoch 29/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5698 - acc: 0.6922\n",
      "Epoch 30/30\n",
      "4028/4028 [==============================] - 0s 7us/sample - loss: 0.5584 - acc: 0.7036\n",
      "attack model no. 2\n",
      "Train on 4040 samples\n",
      "Epoch 1/30\n",
      "4040/4040 [==============================] - 0s 88us/sample - loss: 0.6930 - acc: 0.5225\n",
      "Epoch 2/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6819 - acc: 0.5807\n",
      "Epoch 3/30\n",
      "4040/4040 [==============================] - 0s 5us/sample - loss: 0.6741 - acc: 0.6087\n",
      "Epoch 4/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6675 - acc: 0.6307\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040/4040 [==============================] - 0s 8us/sample - loss: 0.6605 - acc: 0.6319\n",
      "Epoch 6/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6506 - acc: 0.6554\n",
      "Epoch 7/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6431 - acc: 0.6562\n",
      "Epoch 8/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6367 - acc: 0.6671\n",
      "Epoch 9/30\n",
      "4040/4040 [==============================] - 0s 8us/sample - loss: 0.6325 - acc: 0.6653\n",
      "Epoch 10/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6251 - acc: 0.6634\n",
      "Epoch 11/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6183 - acc: 0.6713\n",
      "Epoch 12/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6195 - acc: 0.6631\n",
      "Epoch 13/30\n",
      "4040/4040 [==============================] - 0s 8us/sample - loss: 0.6163 - acc: 0.6676\n",
      "Epoch 14/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6136 - acc: 0.6748\n",
      "Epoch 15/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6072 - acc: 0.6723\n",
      "Epoch 16/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6151 - acc: 0.6725\n",
      "Epoch 17/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.5983 - acc: 0.6795\n",
      "Epoch 18/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6067 - acc: 0.6748\n",
      "Epoch 19/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6049 - acc: 0.6757\n",
      "Epoch 20/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6021 - acc: 0.6777\n",
      "Epoch 21/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6045 - acc: 0.6651\n",
      "Epoch 22/30\n",
      "4040/4040 [==============================] - 0s 8us/sample - loss: 0.5973 - acc: 0.6827\n",
      "Epoch 23/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6000 - acc: 0.6738\n",
      "Epoch 24/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.5992 - acc: 0.6730\n",
      "Epoch 25/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.5936 - acc: 0.6802\n",
      "Epoch 26/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.5991 - acc: 0.6782\n",
      "Epoch 27/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.5929 - acc: 0.6827\n",
      "Epoch 28/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.5992 - acc: 0.6698\n",
      "Epoch 29/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.5989 - acc: 0.6767\n",
      "Epoch 30/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.5991 - acc: 0.6765\n",
      "attack model no. 3\n",
      "Train on 3980 samples\n",
      "Epoch 1/30\n",
      "3980/3980 [==============================] - 0s 94us/sample - loss: 0.7026 - acc: 0.4704\n",
      "Epoch 2/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.6882 - acc: 0.5319\n",
      "Epoch 3/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.6716 - acc: 0.6088\n",
      "Epoch 4/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.6597 - acc: 0.6435\n",
      "Epoch 5/30\n",
      "3980/3980 [==============================] - 0s 5us/sample - loss: 0.6472 - acc: 0.6691\n",
      "Epoch 6/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.6342 - acc: 0.6789\n",
      "Epoch 7/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.6241 - acc: 0.6955\n",
      "Epoch 8/30\n",
      "3980/3980 [==============================] - 0s 7us/sample - loss: 0.6153 - acc: 0.6912\n",
      "Epoch 9/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.6028 - acc: 0.6965\n",
      "Epoch 10/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5963 - acc: 0.6977\n",
      "Epoch 11/30\n",
      "3980/3980 [==============================] - 0s 5us/sample - loss: 0.5888 - acc: 0.7008\n",
      "Epoch 12/30\n",
      "3980/3980 [==============================] - 0s 7us/sample - loss: 0.5796 - acc: 0.7010\n",
      "Epoch 13/30\n",
      "3980/3980 [==============================] - 0s 7us/sample - loss: 0.5680 - acc: 0.7116\n",
      "Epoch 14/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5712 - acc: 0.6995\n",
      "Epoch 15/30\n",
      "3980/3980 [==============================] - 0s 5us/sample - loss: 0.5708 - acc: 0.7108\n",
      "Epoch 16/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5590 - acc: 0.7158\n",
      "Epoch 17/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5646 - acc: 0.7103\n",
      "Epoch 18/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5630 - acc: 0.7073\n",
      "Epoch 19/30\n",
      "3980/3980 [==============================] - 0s 5us/sample - loss: 0.5573 - acc: 0.7088\n",
      "Epoch 20/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5635 - acc: 0.7083\n",
      "Epoch 21/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5560 - acc: 0.7146\n",
      "Epoch 22/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5599 - acc: 0.7108\n",
      "Epoch 23/30\n",
      "3980/3980 [==============================] - 0s 8us/sample - loss: 0.5563 - acc: 0.7158\n",
      "Epoch 24/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5562 - acc: 0.7121\n",
      "Epoch 25/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5612 - acc: 0.6992\n",
      "Epoch 26/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5483 - acc: 0.7211\n",
      "Epoch 27/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5455 - acc: 0.7181\n",
      "Epoch 28/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5518 - acc: 0.7168\n",
      "Epoch 29/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5491 - acc: 0.7186\n",
      "Epoch 30/30\n",
      "3980/3980 [==============================] - 0s 6us/sample - loss: 0.5516 - acc: 0.7128\n",
      "attack model no. 4\n",
      "Train on 4040 samples\n",
      "Epoch 1/30\n",
      "4040/4040 [==============================] - 0s 100us/sample - loss: 0.6935 - acc: 0.5196\n",
      "Epoch 2/30\n",
      "4040/4040 [==============================] - 0s 5us/sample - loss: 0.6800 - acc: 0.5879\n",
      "Epoch 3/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6732 - acc: 0.6121\n",
      "Epoch 4/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6676 - acc: 0.6146\n",
      "Epoch 5/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6608 - acc: 0.6334\n",
      "Epoch 6/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6524 - acc: 0.6483\n",
      "Epoch 7/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6466 - acc: 0.6520\n",
      "Epoch 8/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6433 - acc: 0.6552\n",
      "Epoch 9/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6350 - acc: 0.6629\n",
      "Epoch 10/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6324 - acc: 0.6579\n",
      "Epoch 11/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6353 - acc: 0.6495\n",
      "Epoch 12/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6283 - acc: 0.6527\n",
      "Epoch 13/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6259 - acc: 0.6604\n",
      "Epoch 14/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6171 - acc: 0.6720\n",
      "Epoch 15/30\n",
      "4040/4040 [==============================] - 0s 9us/sample - loss: 0.6185 - acc: 0.6696\n",
      "Epoch 16/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6096 - acc: 0.6671\n",
      "Epoch 17/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6247 - acc: 0.6550\n",
      "Epoch 18/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6125 - acc: 0.6725\n",
      "Epoch 19/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6153 - acc: 0.6639\n",
      "Epoch 20/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6169 - acc: 0.6634\n",
      "Epoch 21/30\n",
      "4040/4040 [==============================] - 0s 7us/sample - loss: 0.6122 - acc: 0.6676\n",
      "Epoch 22/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6141 - acc: 0.6668\n",
      "Epoch 23/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6114 - acc: 0.6688\n",
      "Epoch 24/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6149 - acc: 0.6592\n",
      "Epoch 25/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6030 - acc: 0.6693\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040/4040 [==============================] - 0s 8us/sample - loss: 0.6134 - acc: 0.6606\n",
      "Epoch 27/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6084 - acc: 0.6696\n",
      "Epoch 28/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6089 - acc: 0.6550\n",
      "Epoch 29/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6120 - acc: 0.6683\n",
      "Epoch 30/30\n",
      "4040/4040 [==============================] - 0s 6us/sample - loss: 0.6023 - acc: 0.6817\n",
      "attack model no. 5\n",
      "Train on 3952 samples\n",
      "Epoch 1/30\n",
      "3952/3952 [==============================] - 0s 126us/sample - loss: 0.6846 - acc: 0.5691\n",
      "Epoch 2/30\n",
      "3952/3952 [==============================] - 0s 5us/sample - loss: 0.6770 - acc: 0.6096\n",
      "Epoch 3/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6686 - acc: 0.6349\n",
      "Epoch 4/30\n",
      "3952/3952 [==============================] - 0s 7us/sample - loss: 0.6600 - acc: 0.6531\n",
      "Epoch 5/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6529 - acc: 0.6490\n",
      "Epoch 6/30\n",
      "3952/3952 [==============================] - 0s 5us/sample - loss: 0.6401 - acc: 0.6774\n",
      "Epoch 7/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6386 - acc: 0.6612\n",
      "Epoch 8/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6287 - acc: 0.6630\n",
      "Epoch 9/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6302 - acc: 0.6632\n",
      "Epoch 10/30\n",
      "3952/3952 [==============================] - 0s 5us/sample - loss: 0.6191 - acc: 0.6711\n",
      "Epoch 11/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6200 - acc: 0.6657\n",
      "Epoch 12/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6110 - acc: 0.6741\n",
      "Epoch 13/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6117 - acc: 0.6807\n",
      "Epoch 14/30\n",
      "3952/3952 [==============================] - 0s 5us/sample - loss: 0.6067 - acc: 0.6779\n",
      "Epoch 15/30\n",
      "3952/3952 [==============================] - 0s 5us/sample - loss: 0.6131 - acc: 0.6657\n",
      "Epoch 16/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6040 - acc: 0.6791\n",
      "Epoch 17/30\n",
      "3952/3952 [==============================] - ETA: 0s - loss: 0.5985 - acc: 0.681 - 0s 7us/sample - loss: 0.6054 - acc: 0.6759\n",
      "Epoch 18/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6086 - acc: 0.6670\n",
      "Epoch 19/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6034 - acc: 0.6865\n",
      "Epoch 20/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.5969 - acc: 0.6850\n",
      "Epoch 21/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.5933 - acc: 0.6903\n",
      "Epoch 22/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6037 - acc: 0.6703\n",
      "Epoch 23/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.5910 - acc: 0.6908\n",
      "Epoch 24/30\n",
      "3952/3952 [==============================] - 0s 5us/sample - loss: 0.6015 - acc: 0.6713\n",
      "Epoch 25/30\n",
      "3952/3952 [==============================] - 0s 7us/sample - loss: 0.6056 - acc: 0.6660\n",
      "Epoch 26/30\n",
      "3952/3952 [==============================] - 0s 8us/sample - loss: 0.5969 - acc: 0.6774\n",
      "Epoch 27/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.5886 - acc: 0.6840\n",
      "Epoch 28/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.5976 - acc: 0.6738\n",
      "Epoch 29/30\n",
      "3952/3952 [==============================] - 0s 6us/sample - loss: 0.6002 - acc: 0.6695\n",
      "Epoch 30/30\n",
      "3952/3952 [==============================] - 0s 5us/sample - loss: 0.5978 - acc: 0.6797\n",
      "attack model no. 6\n",
      "Train on 4032 samples\n",
      "Epoch 1/30\n",
      "4032/4032 [==============================] - 0s 96us/sample - loss: 0.7010 - acc: 0.4727\n",
      "Epoch 2/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6889 - acc: 0.5308\n",
      "Epoch 3/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6799 - acc: 0.5744\n",
      "Epoch 4/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6693 - acc: 0.6069\n",
      "Epoch 5/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6617 - acc: 0.6347\n",
      "Epoch 6/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6541 - acc: 0.6379\n",
      "Epoch 7/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6473 - acc: 0.6513\n",
      "Epoch 8/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6444 - acc: 0.6538\n",
      "Epoch 9/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6337 - acc: 0.6649\n",
      "Epoch 10/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6309 - acc: 0.6674\n",
      "Epoch 11/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6296 - acc: 0.6632\n",
      "Epoch 12/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6228 - acc: 0.6684\n",
      "Epoch 13/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6196 - acc: 0.6696\n",
      "Epoch 14/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6171 - acc: 0.6689\n",
      "Epoch 15/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6195 - acc: 0.6669\n",
      "Epoch 16/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6205 - acc: 0.6652\n",
      "Epoch 17/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6121 - acc: 0.6749\n",
      "Epoch 18/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6210 - acc: 0.6615\n",
      "Epoch 19/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6042 - acc: 0.6734\n",
      "Epoch 20/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6201 - acc: 0.6580\n",
      "Epoch 21/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.6123 - acc: 0.6706\n",
      "Epoch 22/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6081 - acc: 0.6771\n",
      "Epoch 23/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6115 - acc: 0.6667\n",
      "Epoch 24/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6044 - acc: 0.6741\n",
      "Epoch 25/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6063 - acc: 0.6667\n",
      "Epoch 26/30\n",
      "4032/4032 [==============================] - 0s 6us/sample - loss: 0.5980 - acc: 0.6808\n",
      "Epoch 27/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.5968 - acc: 0.6850\n",
      "Epoch 28/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6007 - acc: 0.6753\n",
      "Epoch 29/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6011 - acc: 0.6763\n",
      "Epoch 30/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6006 - acc: 0.6766\n",
      "attack model no. 7\n",
      "Train on 4104 samples\n",
      "Epoch 1/30\n",
      "4104/4104 [==============================] - 0s 101us/sample - loss: 0.6983 - acc: 0.5015\n",
      "Epoch 2/30\n",
      "4104/4104 [==============================] - 0s 5us/sample - loss: 0.6829 - acc: 0.5655\n",
      "Epoch 3/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6709 - acc: 0.6413\n",
      "Epoch 4/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6614 - acc: 0.6586\n",
      "Epoch 5/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6542 - acc: 0.6564\n",
      "Epoch 6/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6455 - acc: 0.6635\n",
      "Epoch 7/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.6338 - acc: 0.6774\n",
      "Epoch 8/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.6233 - acc: 0.6796\n",
      "Epoch 9/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6231 - acc: 0.6689\n",
      "Epoch 10/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6184 - acc: 0.6723\n",
      "Epoch 11/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.6010 - acc: 0.6896\n",
      "Epoch 12/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6068 - acc: 0.6747\n",
      "Epoch 13/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6038 - acc: 0.6752\n",
      "Epoch 14/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.6002 - acc: 0.6730\n",
      "Epoch 15/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5985 - acc: 0.6735\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.6024 - acc: 0.6718\n",
      "Epoch 17/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.5967 - acc: 0.6796\n",
      "Epoch 18/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.5943 - acc: 0.6762\n",
      "Epoch 19/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.5936 - acc: 0.6869\n",
      "Epoch 20/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.5878 - acc: 0.6827\n",
      "Epoch 21/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.5925 - acc: 0.6813\n",
      "Epoch 22/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.5820 - acc: 0.6869\n",
      "Epoch 23/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.5933 - acc: 0.6767\n",
      "Epoch 24/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.5789 - acc: 0.6901\n",
      "Epoch 25/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.5850 - acc: 0.6849\n",
      "Epoch 26/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5870 - acc: 0.6847\n",
      "Epoch 27/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.5862 - acc: 0.6888\n",
      "Epoch 28/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.5835 - acc: 0.6942\n",
      "Epoch 29/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.5902 - acc: 0.6854\n",
      "Epoch 30/30\n",
      "4104/4104 [==============================] - 0s 6us/sample - loss: 0.5832 - acc: 0.6940\n",
      "attack model no. 8\n",
      "Train on 3948 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 0s 103us/sample - loss: 0.6940 - acc: 0.5018\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 0s 5us/sample - loss: 0.6862 - acc: 0.5502\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 0s 5us/sample - loss: 0.6805 - acc: 0.5790\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 0s 9us/sample - loss: 0.6712 - acc: 0.6155\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 0s 5us/sample - loss: 0.6697 - acc: 0.6122\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6665 - acc: 0.6223\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6608 - acc: 0.6239\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6541 - acc: 0.6322\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6509 - acc: 0.6312\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6511 - acc: 0.6373\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6431 - acc: 0.6393\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6474 - acc: 0.6277\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6481 - acc: 0.6342\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6412 - acc: 0.6302\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 0s 7us/sample - loss: 0.6332 - acc: 0.6464\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6338 - acc: 0.6459\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6344 - acc: 0.6373\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6327 - acc: 0.6429\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6345 - acc: 0.6289\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 0s 5us/sample - loss: 0.6322 - acc: 0.6317\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 0s 5us/sample - loss: 0.6312 - acc: 0.6350\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 0s 7us/sample - loss: 0.6276 - acc: 0.6373\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6260 - acc: 0.6337\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 0s 7us/sample - loss: 0.6308 - acc: 0.6396\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6270 - acc: 0.6348\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 0s 7us/sample - loss: 0.6259 - acc: 0.6363\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6254 - acc: 0.6386\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 0s 6us/sample - loss: 0.6209 - acc: 0.6383\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 0s 7us/sample - loss: 0.6245 - acc: 0.6439\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 0s 7us/sample - loss: 0.6260 - acc: 0.6408\n",
      "attack model no. 9\n",
      "Train on 3940 samples\n",
      "Epoch 1/30\n",
      "3940/3940 [==============================] - 0s 106us/sample - loss: 0.7243 - acc: 0.4835\n",
      "Epoch 2/30\n",
      "3940/3940 [==============================] - 0s 5us/sample - loss: 0.6967 - acc: 0.5180\n",
      "Epoch 3/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6815 - acc: 0.5734\n",
      "Epoch 4/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6675 - acc: 0.6053\n",
      "Epoch 5/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6573 - acc: 0.6302\n",
      "Epoch 6/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.6494 - acc: 0.6434\n",
      "Epoch 7/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6389 - acc: 0.6703\n",
      "Epoch 8/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6329 - acc: 0.6794\n",
      "Epoch 9/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6230 - acc: 0.6888\n",
      "Epoch 10/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6126 - acc: 0.6934\n",
      "Epoch 11/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.6090 - acc: 0.6916\n",
      "Epoch 12/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.6009 - acc: 0.6919\n",
      "Epoch 13/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.5890 - acc: 0.7058\n",
      "Epoch 14/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5988 - acc: 0.6916\n",
      "Epoch 15/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5874 - acc: 0.6964\n",
      "Epoch 16/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.5819 - acc: 0.7005\n",
      "Epoch 17/30\n",
      "3940/3940 [==============================] - 0s 9us/sample - loss: 0.5782 - acc: 0.7038\n",
      "Epoch 18/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.5780 - acc: 0.6962\n",
      "Epoch 19/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5832 - acc: 0.6962\n",
      "Epoch 20/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.5664 - acc: 0.7053\n",
      "Epoch 21/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.5745 - acc: 0.6944\n",
      "Epoch 22/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5739 - acc: 0.6992\n",
      "Epoch 23/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5725 - acc: 0.6959\n",
      "Epoch 24/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5739 - acc: 0.6944\n",
      "Epoch 25/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5647 - acc: 0.7030\n",
      "Epoch 26/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5647 - acc: 0.6942\n",
      "Epoch 27/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5700 - acc: 0.6921\n",
      "Epoch 28/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.5603 - acc: 0.7020\n",
      "Epoch 29/30\n",
      "3940/3940 [==============================] - 0s 7us/sample - loss: 0.5583 - acc: 0.7096\n",
      "Epoch 30/30\n",
      "3940/3940 [==============================] - 0s 6us/sample - loss: 0.5584 - acc: 0.7058\n",
      "attack model no. 0\n",
      "Train on 3996 samples\n",
      "Epoch 1/30\n",
      "3996/3996 [==============================] - 0s 113us/sample - loss: 0.6907 - acc: 0.5265\n",
      "Epoch 2/30\n",
      "3996/3996 [==============================] - 0s 5us/sample - loss: 0.6837 - acc: 0.5628\n",
      "Epoch 3/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6773 - acc: 0.5928\n",
      "Epoch 4/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6752 - acc: 0.5908\n",
      "Epoch 5/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6686 - acc: 0.6139\n",
      "Epoch 6/30\n",
      "3996/3996 [==============================] - 0s 8us/sample - loss: 0.6631 - acc: 0.6209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "3996/3996 [==============================] - 0s 8us/sample - loss: 0.6628 - acc: 0.6236\n",
      "Epoch 8/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6553 - acc: 0.6329\n",
      "Epoch 9/30\n",
      "3996/3996 [==============================] - 0s 10us/sample - loss: 0.6589 - acc: 0.6219\n",
      "Epoch 10/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6526 - acc: 0.6346\n",
      "Epoch 11/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6513 - acc: 0.6231\n",
      "Epoch 12/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6529 - acc: 0.6284\n",
      "Epoch 13/30\n",
      "3996/3996 [==============================] - 0s 10us/sample - loss: 0.6515 - acc: 0.6286\n",
      "Epoch 14/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6456 - acc: 0.6366\n",
      "Epoch 15/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6456 - acc: 0.6359\n",
      "Epoch 16/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6424 - acc: 0.6401\n",
      "Epoch 17/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6447 - acc: 0.6314\n",
      "Epoch 18/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6442 - acc: 0.6339\n",
      "Epoch 19/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6392 - acc: 0.6344\n",
      "Epoch 20/30\n",
      "3996/3996 [==============================] - 0s 8us/sample - loss: 0.6388 - acc: 0.6344\n",
      "Epoch 21/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6376 - acc: 0.6311\n",
      "Epoch 22/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6340 - acc: 0.6379\n",
      "Epoch 23/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6365 - acc: 0.6316\n",
      "Epoch 24/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6351 - acc: 0.6329\n",
      "Epoch 25/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6348 - acc: 0.6291\n",
      "Epoch 26/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6368 - acc: 0.6294\n",
      "Epoch 27/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6284 - acc: 0.6454\n",
      "Epoch 28/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6298 - acc: 0.6476\n",
      "Epoch 29/30\n",
      "3996/3996 [==============================] - 0s 7us/sample - loss: 0.6315 - acc: 0.6361\n",
      "Epoch 30/30\n",
      "3996/3996 [==============================] - 0s 6us/sample - loss: 0.6269 - acc: 0.6376\n",
      "attack model no. 1\n",
      "Train on 4188 samples\n",
      "Epoch 1/30\n",
      "4188/4188 [==============================] - 0s 113us/sample - loss: 0.6851 - acc: 0.5604\n",
      "Epoch 2/30\n",
      "4188/4188 [==============================] - 0s 6us/sample - loss: 0.6669 - acc: 0.6337\n",
      "Epoch 3/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.6541 - acc: 0.6540\n",
      "Epoch 4/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.6384 - acc: 0.6726\n",
      "Epoch 5/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.6263 - acc: 0.6872\n",
      "Epoch 6/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.6183 - acc: 0.6831\n",
      "Epoch 7/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.6048 - acc: 0.6965\n",
      "Epoch 8/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5958 - acc: 0.6987\n",
      "Epoch 9/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5930 - acc: 0.6968\n",
      "Epoch 10/30\n",
      "4188/4188 [==============================] - 0s 9us/sample - loss: 0.5858 - acc: 0.7008\n",
      "Epoch 11/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5778 - acc: 0.7053\n",
      "Epoch 12/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5834 - acc: 0.6984\n",
      "Epoch 13/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5784 - acc: 0.6982\n",
      "Epoch 14/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5820 - acc: 0.6917\n",
      "Epoch 15/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5783 - acc: 0.6927\n",
      "Epoch 16/30\n",
      "4188/4188 [==============================] - 0s 9us/sample - loss: 0.5704 - acc: 0.6991\n",
      "Epoch 17/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5714 - acc: 0.6913\n",
      "Epoch 18/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5690 - acc: 0.7008\n",
      "Epoch 19/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5672 - acc: 0.7011\n",
      "Epoch 20/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5703 - acc: 0.6896\n",
      "Epoch 21/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5744 - acc: 0.6944\n",
      "Epoch 22/30\n",
      "4188/4188 [==============================] - 0s 6us/sample - loss: 0.5684 - acc: 0.6991\n",
      "Epoch 23/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5693 - acc: 0.6968\n",
      "Epoch 24/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5640 - acc: 0.7044\n",
      "Epoch 25/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5615 - acc: 0.7051\n",
      "Epoch 26/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5651 - acc: 0.7020\n",
      "Epoch 27/30\n",
      "4188/4188 [==============================] - 0s 8us/sample - loss: 0.5614 - acc: 0.7077\n",
      "Epoch 28/30\n",
      "4188/4188 [==============================] - 0s 9us/sample - loss: 0.5591 - acc: 0.7082\n",
      "Epoch 29/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5590 - acc: 0.7046\n",
      "Epoch 30/30\n",
      "4188/4188 [==============================] - 0s 7us/sample - loss: 0.5538 - acc: 0.7178\n",
      "attack model no. 2\n",
      "Train on 3936 samples\n",
      "Epoch 1/30\n",
      "3936/3936 [==============================] - 0s 121us/sample - loss: 0.6996 - acc: 0.4982\n",
      "Epoch 2/30\n",
      "3936/3936 [==============================] - 0s 5us/sample - loss: 0.6855 - acc: 0.5655\n",
      "Epoch 3/30\n",
      "3936/3936 [==============================] - 0s 8us/sample - loss: 0.6735 - acc: 0.6314\n",
      "Epoch 4/30\n",
      "3936/3936 [==============================] - 0s 8us/sample - loss: 0.6660 - acc: 0.6496\n",
      "Epoch 5/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6569 - acc: 0.6583\n",
      "Epoch 6/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6482 - acc: 0.6735\n",
      "Epoch 7/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6400 - acc: 0.6806\n",
      "Epoch 8/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6283 - acc: 0.6791\n",
      "Epoch 9/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6189 - acc: 0.6809\n",
      "Epoch 10/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6171 - acc: 0.6799\n",
      "Epoch 11/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6101 - acc: 0.6811\n",
      "Epoch 12/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.6000 - acc: 0.6880\n",
      "Epoch 13/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.6027 - acc: 0.6768\n",
      "Epoch 14/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5942 - acc: 0.6898\n",
      "Epoch 15/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5882 - acc: 0.6946\n",
      "Epoch 16/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5948 - acc: 0.6819\n",
      "Epoch 17/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5938 - acc: 0.6781\n",
      "Epoch 18/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.5896 - acc: 0.6883\n",
      "Epoch 19/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.5903 - acc: 0.6900\n",
      "Epoch 20/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.5895 - acc: 0.6893\n",
      "Epoch 21/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5914 - acc: 0.6850\n",
      "Epoch 22/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5887 - acc: 0.6837\n",
      "Epoch 23/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.5862 - acc: 0.6890\n",
      "Epoch 24/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5821 - acc: 0.6885\n",
      "Epoch 25/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5807 - acc: 0.6961\n",
      "Epoch 26/30\n",
      "3936/3936 [==============================] - 0s 6us/sample - loss: 0.5858 - acc: 0.6804\n",
      "Epoch 27/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.5814 - acc: 0.6862\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3936/3936 [==============================] - 0s 9us/sample - loss: 0.5842 - acc: 0.6842\n",
      "Epoch 29/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.5777 - acc: 0.6916\n",
      "Epoch 30/30\n",
      "3936/3936 [==============================] - 0s 7us/sample - loss: 0.5782 - acc: 0.6860\n",
      "attack model no. 3\n",
      "Train on 4020 samples\n",
      "Epoch 1/30\n",
      "4020/4020 [==============================] - 0s 118us/sample - loss: 0.6783 - acc: 0.5863\n",
      "Epoch 2/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.6620 - acc: 0.6413\n",
      "Epoch 3/30\n",
      "4020/4020 [==============================] - 0s 6us/sample - loss: 0.6474 - acc: 0.6721\n",
      "Epoch 4/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.6386 - acc: 0.6871\n",
      "Epoch 5/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.6266 - acc: 0.6958\n",
      "Epoch 6/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.6135 - acc: 0.7095\n",
      "Epoch 7/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6024 - acc: 0.7167\n",
      "Epoch 8/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5987 - acc: 0.7072\n",
      "Epoch 9/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5881 - acc: 0.7221\n",
      "Epoch 10/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5946 - acc: 0.6968\n",
      "Epoch 11/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5776 - acc: 0.7174\n",
      "Epoch 12/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5793 - acc: 0.6998\n",
      "Epoch 13/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5681 - acc: 0.7092\n",
      "Epoch 14/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5646 - acc: 0.7157\n",
      "Epoch 15/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5632 - acc: 0.7169\n",
      "Epoch 16/30\n",
      "4020/4020 [==============================] - 0s 12us/sample - loss: 0.5623 - acc: 0.7194\n",
      "Epoch 17/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5581 - acc: 0.7209\n",
      "Epoch 18/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5652 - acc: 0.7090\n",
      "Epoch 19/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5571 - acc: 0.7132\n",
      "Epoch 20/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5623 - acc: 0.6990\n",
      "Epoch 21/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5544 - acc: 0.7174\n",
      "Epoch 22/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5539 - acc: 0.7129\n",
      "Epoch 23/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5528 - acc: 0.7174\n",
      "Epoch 24/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5570 - acc: 0.7102\n",
      "Epoch 25/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5526 - acc: 0.7154\n",
      "Epoch 26/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5552 - acc: 0.7174\n",
      "Epoch 27/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5572 - acc: 0.7045\n",
      "Epoch 28/30\n",
      "4020/4020 [==============================] - 0s 9us/sample - loss: 0.5449 - acc: 0.7172\n",
      "Epoch 29/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.5546 - acc: 0.7139\n",
      "Epoch 30/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.5486 - acc: 0.7124\n",
      "attack model no. 4\n",
      "Train on 3956 samples\n",
      "Epoch 1/30\n",
      "3956/3956 [==============================] - 0s 124us/sample - loss: 0.7001 - acc: 0.4942\n",
      "Epoch 2/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6874 - acc: 0.5427\n",
      "Epoch 3/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6776 - acc: 0.5890\n",
      "Epoch 4/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6723 - acc: 0.6193\n",
      "Epoch 5/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6640 - acc: 0.6317\n",
      "Epoch 6/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6545 - acc: 0.6529\n",
      "Epoch 7/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.6497 - acc: 0.6519\n",
      "Epoch 8/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6461 - acc: 0.6494\n",
      "Epoch 9/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.6351 - acc: 0.6653\n",
      "Epoch 10/30\n",
      "3956/3956 [==============================] - 0s 8us/sample - loss: 0.6302 - acc: 0.6633\n",
      "Epoch 11/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6196 - acc: 0.6752\n",
      "Epoch 12/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.6108 - acc: 0.6764\n",
      "Epoch 13/30\n",
      "3956/3956 [==============================] - 0s 8us/sample - loss: 0.6111 - acc: 0.6686\n",
      "Epoch 14/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.6100 - acc: 0.6752\n",
      "Epoch 15/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.5966 - acc: 0.6898\n",
      "Epoch 16/30\n",
      "3956/3956 [==============================] - 0s 8us/sample - loss: 0.5983 - acc: 0.6840\n",
      "Epoch 17/30\n",
      "3956/3956 [==============================] - 0s 9us/sample - loss: 0.6035 - acc: 0.6646\n",
      "Epoch 18/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.6026 - acc: 0.6772\n",
      "Epoch 19/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.5948 - acc: 0.6840\n",
      "Epoch 20/30\n",
      "3956/3956 [==============================] - 0s 8us/sample - loss: 0.6004 - acc: 0.6792\n",
      "Epoch 21/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.6015 - acc: 0.6747\n",
      "Epoch 22/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.6043 - acc: 0.6711\n",
      "Epoch 23/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.5979 - acc: 0.6790\n",
      "Epoch 24/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.6005 - acc: 0.6759\n",
      "Epoch 25/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.5968 - acc: 0.6797\n",
      "Epoch 26/30\n",
      "3956/3956 [==============================] - 0s 9us/sample - loss: 0.5981 - acc: 0.6696\n",
      "Epoch 27/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.5892 - acc: 0.6777\n",
      "Epoch 28/30\n",
      "3956/3956 [==============================] - 0s 7us/sample - loss: 0.5972 - acc: 0.6767\n",
      "Epoch 29/30\n",
      "3956/3956 [==============================] - 0s 8us/sample - loss: 0.5904 - acc: 0.6838\n",
      "Epoch 30/30\n",
      "3956/3956 [==============================] - 0s 6us/sample - loss: 0.5887 - acc: 0.6812\n",
      "attack model no. 5\n",
      "Train on 3900 samples\n",
      "Epoch 1/30\n",
      "3900/3900 [==============================] - 0s 125us/sample - loss: 0.6985 - acc: 0.4990\n",
      "Epoch 2/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.6851 - acc: 0.5097\n",
      "Epoch 3/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.6760 - acc: 0.5656\n",
      "Epoch 4/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.6678 - acc: 0.6249\n",
      "Epoch 5/30\n",
      "3900/3900 [==============================] - 0s 8us/sample - loss: 0.6594 - acc: 0.6628\n",
      "Epoch 6/30\n",
      "3900/3900 [==============================] - 0s 8us/sample - loss: 0.6485 - acc: 0.6790\n",
      "Epoch 7/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.6398 - acc: 0.6808\n",
      "Epoch 8/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.6311 - acc: 0.6851\n",
      "Epoch 9/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.6244 - acc: 0.6859\n",
      "Epoch 10/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.6129 - acc: 0.6949\n",
      "Epoch 11/30\n",
      "3900/3900 [==============================] - 0s 8us/sample - loss: 0.6040 - acc: 0.6997\n",
      "Epoch 12/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.6007 - acc: 0.6928\n",
      "Epoch 13/30\n",
      "3900/3900 [==============================] - 0s 9us/sample - loss: 0.5939 - acc: 0.6908\n",
      "Epoch 14/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5886 - acc: 0.6931\n",
      "Epoch 15/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.5792 - acc: 0.6969\n",
      "Epoch 16/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.5836 - acc: 0.6877\n",
      "Epoch 17/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5801 - acc: 0.7005\n",
      "Epoch 18/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.5778 - acc: 0.6985\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5682 - acc: 0.7049\n",
      "Epoch 20/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5750 - acc: 0.6946\n",
      "Epoch 21/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5722 - acc: 0.7000\n",
      "Epoch 22/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.5687 - acc: 0.7021\n",
      "Epoch 23/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5612 - acc: 0.7105\n",
      "Epoch 24/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5727 - acc: 0.7026\n",
      "Epoch 25/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5663 - acc: 0.6995\n",
      "Epoch 26/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5589 - acc: 0.7056\n",
      "Epoch 27/30\n",
      "3900/3900 [==============================] - 0s 6us/sample - loss: 0.5672 - acc: 0.7074\n",
      "Epoch 28/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5641 - acc: 0.7074\n",
      "Epoch 29/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5735 - acc: 0.6979\n",
      "Epoch 30/30\n",
      "3900/3900 [==============================] - 0s 7us/sample - loss: 0.5673 - acc: 0.7026\n",
      "attack model no. 6\n",
      "Train on 4008 samples\n",
      "Epoch 1/30\n",
      "4008/4008 [==============================] - 1s 125us/sample - loss: 0.6845 - acc: 0.5601\n",
      "Epoch 2/30\n",
      "4008/4008 [==============================] - 0s 6us/sample - loss: 0.6776 - acc: 0.5986\n",
      "Epoch 3/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6712 - acc: 0.6018\n",
      "Epoch 4/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6654 - acc: 0.6235\n",
      "Epoch 5/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6599 - acc: 0.6447\n",
      "Epoch 6/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6550 - acc: 0.6380\n",
      "Epoch 7/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6488 - acc: 0.6547\n",
      "Epoch 8/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6470 - acc: 0.6562\n",
      "Epoch 9/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6440 - acc: 0.6527\n",
      "Epoch 10/30\n",
      "4008/4008 [==============================] - 0s 10us/sample - loss: 0.6392 - acc: 0.6572\n",
      "Epoch 11/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6395 - acc: 0.6567\n",
      "Epoch 12/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6336 - acc: 0.6577\n",
      "Epoch 13/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6305 - acc: 0.6552\n",
      "Epoch 14/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6294 - acc: 0.6534\n",
      "Epoch 15/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6275 - acc: 0.6552\n",
      "Epoch 16/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6230 - acc: 0.6624\n",
      "Epoch 17/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6208 - acc: 0.6592\n",
      "Epoch 18/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6146 - acc: 0.6712\n",
      "Epoch 19/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6142 - acc: 0.6669\n",
      "Epoch 20/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6171 - acc: 0.6634\n",
      "Epoch 21/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6170 - acc: 0.6727\n",
      "Epoch 22/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6106 - acc: 0.6722\n",
      "Epoch 23/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6202 - acc: 0.6614\n",
      "Epoch 24/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6177 - acc: 0.6599\n",
      "Epoch 25/30\n",
      "4008/4008 [==============================] - 0s 9us/sample - loss: 0.6221 - acc: 0.6577\n",
      "Epoch 26/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6118 - acc: 0.6664\n",
      "Epoch 27/30\n",
      "4008/4008 [==============================] - 0s 7us/sample - loss: 0.6161 - acc: 0.6554\n",
      "Epoch 28/30\n",
      "4008/4008 [==============================] - 0s 9us/sample - loss: 0.6108 - acc: 0.6637\n",
      "Epoch 29/30\n",
      "4008/4008 [==============================] - 0s 9us/sample - loss: 0.6175 - acc: 0.6559\n",
      "Epoch 30/30\n",
      "4008/4008 [==============================] - 0s 8us/sample - loss: 0.6108 - acc: 0.6594\n",
      "attack model no. 7\n",
      "Train on 4064 samples\n",
      "Epoch 1/30\n",
      "4064/4064 [==============================] - 1s 124us/sample - loss: 0.6886 - acc: 0.5455\n",
      "Epoch 2/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6780 - acc: 0.6216\n",
      "Epoch 3/30\n",
      "4064/4064 [==============================] - 0s 9us/sample - loss: 0.6726 - acc: 0.6344\n",
      "Epoch 4/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.6659 - acc: 0.6471\n",
      "Epoch 5/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6617 - acc: 0.6452\n",
      "Epoch 6/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.6520 - acc: 0.6587\n",
      "Epoch 7/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6427 - acc: 0.6710\n",
      "Epoch 8/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6383 - acc: 0.6666\n",
      "Epoch 9/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6309 - acc: 0.6752\n",
      "Epoch 10/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.6282 - acc: 0.6735\n",
      "Epoch 11/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.6159 - acc: 0.6781\n",
      "Epoch 12/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6101 - acc: 0.6828\n",
      "Epoch 13/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.6089 - acc: 0.6818\n",
      "Epoch 14/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6066 - acc: 0.6754\n",
      "Epoch 15/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6070 - acc: 0.6786\n",
      "Epoch 16/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6026 - acc: 0.6833\n",
      "Epoch 17/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.6022 - acc: 0.6794\n",
      "Epoch 18/30\n",
      "4064/4064 [==============================] - 0s 9us/sample - loss: 0.5976 - acc: 0.6786\n",
      "Epoch 19/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.5948 - acc: 0.6845\n",
      "Epoch 20/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.5929 - acc: 0.6806\n",
      "Epoch 21/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.5861 - acc: 0.6875\n",
      "Epoch 22/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.5908 - acc: 0.6855\n",
      "Epoch 23/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.5915 - acc: 0.6880\n",
      "Epoch 24/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.5866 - acc: 0.6838\n",
      "Epoch 25/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.5792 - acc: 0.6983\n",
      "Epoch 26/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.5850 - acc: 0.6860\n",
      "Epoch 27/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.5912 - acc: 0.6745\n",
      "Epoch 28/30\n",
      "4064/4064 [==============================] - 0s 8us/sample - loss: 0.5876 - acc: 0.6791\n",
      "Epoch 29/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.5926 - acc: 0.6777\n",
      "Epoch 30/30\n",
      "4064/4064 [==============================] - 0s 7us/sample - loss: 0.5795 - acc: 0.6914\n",
      "attack model no. 8\n",
      "Train on 3968 samples\n",
      "Epoch 1/30\n",
      "3968/3968 [==============================] - 1s 128us/sample - loss: 0.7035 - acc: 0.4506\n",
      "Epoch 2/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6958 - acc: 0.4887\n",
      "Epoch 3/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6859 - acc: 0.5605\n",
      "Epoch 4/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6793 - acc: 0.5935\n",
      "Epoch 5/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6735 - acc: 0.6066\n",
      "Epoch 6/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6692 - acc: 0.6152\n",
      "Epoch 7/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6607 - acc: 0.6280\n",
      "Epoch 8/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6576 - acc: 0.6247\n",
      "Epoch 9/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6522 - acc: 0.6268\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6495 - acc: 0.6316\n",
      "Epoch 11/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6498 - acc: 0.6273\n",
      "Epoch 12/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6513 - acc: 0.6250\n",
      "Epoch 13/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6464 - acc: 0.6308\n",
      "Epoch 14/30\n",
      "3968/3968 [==============================] - 0s 10us/sample - loss: 0.6456 - acc: 0.6283\n",
      "Epoch 15/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6420 - acc: 0.6265\n",
      "Epoch 16/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6395 - acc: 0.6348\n",
      "Epoch 17/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6422 - acc: 0.6225\n",
      "Epoch 18/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6377 - acc: 0.6265\n",
      "Epoch 19/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6400 - acc: 0.6255\n",
      "Epoch 20/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6345 - acc: 0.6348\n",
      "Epoch 21/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6318 - acc: 0.6371\n",
      "Epoch 22/30\n",
      "3968/3968 [==============================] - 0s 8us/sample - loss: 0.6355 - acc: 0.6295\n",
      "Epoch 23/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6292 - acc: 0.6406\n",
      "Epoch 24/30\n",
      "3968/3968 [==============================] - 0s 6us/sample - loss: 0.6268 - acc: 0.6479\n",
      "Epoch 25/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6268 - acc: 0.6361\n",
      "Epoch 26/30\n",
      "3968/3968 [==============================] - 0s 8us/sample - loss: 0.6293 - acc: 0.6341\n",
      "Epoch 27/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6288 - acc: 0.6358\n",
      "Epoch 28/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6254 - acc: 0.6426\n",
      "Epoch 29/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6280 - acc: 0.6376\n",
      "Epoch 30/30\n",
      "3968/3968 [==============================] - 0s 7us/sample - loss: 0.6249 - acc: 0.6439\n",
      "attack model no. 9\n",
      "Train on 3964 samples\n",
      "Epoch 1/30\n",
      "3964/3964 [==============================] - 1s 132us/sample - loss: 0.6907 - acc: 0.5237\n",
      "Epoch 2/30\n",
      "3964/3964 [==============================] - 0s 5us/sample - loss: 0.6806 - acc: 0.5709\n",
      "Epoch 3/30\n",
      "3964/3964 [==============================] - 0s 6us/sample - loss: 0.6670 - acc: 0.6357\n",
      "Epoch 4/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.6564 - acc: 0.6645\n",
      "Epoch 5/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.6463 - acc: 0.6789\n",
      "Epoch 6/30\n",
      "3964/3964 [==============================] - 0s 6us/sample - loss: 0.6331 - acc: 0.6942\n",
      "Epoch 7/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.6244 - acc: 0.6922\n",
      "Epoch 8/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.6135 - acc: 0.6932\n",
      "Epoch 9/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.6031 - acc: 0.7001\n",
      "Epoch 10/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5953 - acc: 0.6953\n",
      "Epoch 11/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5822 - acc: 0.7056\n",
      "Epoch 12/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5826 - acc: 0.6965\n",
      "Epoch 13/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5748 - acc: 0.7021\n",
      "Epoch 14/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5748 - acc: 0.7013\n",
      "Epoch 15/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5713 - acc: 0.6965\n",
      "Epoch 16/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5820 - acc: 0.6819\n",
      "Epoch 17/30\n",
      "3964/3964 [==============================] - 0s 8us/sample - loss: 0.5658 - acc: 0.6988\n",
      "Epoch 18/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5654 - acc: 0.7006\n",
      "Epoch 19/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5635 - acc: 0.6942\n",
      "Epoch 20/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5587 - acc: 0.7043\n",
      "Epoch 21/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5548 - acc: 0.7079\n",
      "Epoch 22/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5575 - acc: 0.6983\n",
      "Epoch 23/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5613 - acc: 0.6975\n",
      "Epoch 24/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5611 - acc: 0.7031\n",
      "Epoch 25/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5547 - acc: 0.7061\n",
      "Epoch 26/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5493 - acc: 0.7152\n",
      "Epoch 27/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5532 - acc: 0.7104\n",
      "Epoch 28/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5469 - acc: 0.7132\n",
      "Epoch 29/30\n",
      "3964/3964 [==============================] - 0s 7us/sample - loss: 0.5456 - acc: 0.7205\n",
      "Epoch 30/30\n",
      "3964/3964 [==============================] - 0s 8us/sample - loss: 0.5556 - acc: 0.7086\n",
      "attack model no. 0\n",
      "Train on 3976 samples\n",
      "Epoch 1/30\n",
      "3976/3976 [==============================] - 1s 142us/sample - loss: 0.6996 - acc: 0.4703\n",
      "Epoch 2/30\n",
      "3976/3976 [==============================] - 0s 6us/sample - loss: 0.6891 - acc: 0.5355\n",
      "Epoch 3/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6859 - acc: 0.5578\n",
      "Epoch 4/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6806 - acc: 0.5727\n",
      "Epoch 5/30\n",
      "3976/3976 [==============================] - 0s 10us/sample - loss: 0.6768 - acc: 0.5996\n",
      "Epoch 6/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6723 - acc: 0.6190\n",
      "Epoch 7/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6691 - acc: 0.6061\n",
      "Epoch 8/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6618 - acc: 0.6247\n",
      "Epoch 9/30\n",
      "3976/3976 [==============================] - 0s 10us/sample - loss: 0.6583 - acc: 0.6323\n",
      "Epoch 10/30\n",
      "3976/3976 [==============================] - 0s 8us/sample - loss: 0.6584 - acc: 0.6310\n",
      "Epoch 11/30\n",
      "3976/3976 [==============================] - 0s 9us/sample - loss: 0.6524 - acc: 0.6295\n",
      "Epoch 12/30\n",
      "3976/3976 [==============================] - 0s 6us/sample - loss: 0.6573 - acc: 0.6235\n",
      "Epoch 13/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6470 - acc: 0.6346\n",
      "Epoch 14/30\n",
      "3976/3976 [==============================] - 0s 8us/sample - loss: 0.6483 - acc: 0.6358\n",
      "Epoch 15/30\n",
      "3976/3976 [==============================] - 0s 8us/sample - loss: 0.6446 - acc: 0.6341\n",
      "Epoch 16/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6378 - acc: 0.6378\n",
      "Epoch 17/30\n",
      "3976/3976 [==============================] - 0s 8us/sample - loss: 0.6341 - acc: 0.6431\n",
      "Epoch 18/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6420 - acc: 0.6305\n",
      "Epoch 19/30\n",
      "3976/3976 [==============================] - 0s 8us/sample - loss: 0.6404 - acc: 0.6273\n",
      "Epoch 20/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6350 - acc: 0.6368\n",
      "Epoch 21/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6330 - acc: 0.6346\n",
      "Epoch 22/30\n",
      "3976/3976 [==============================] - 0s 9us/sample - loss: 0.6303 - acc: 0.6353\n",
      "Epoch 23/30\n",
      "3976/3976 [==============================] - 0s 9us/sample - loss: 0.6313 - acc: 0.6361\n",
      "Epoch 24/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6252 - acc: 0.6421\n",
      "Epoch 25/30\n",
      "3976/3976 [==============================] - 0s 8us/sample - loss: 0.6302 - acc: 0.6265\n",
      "Epoch 26/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6202 - acc: 0.6436\n",
      "Epoch 27/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6266 - acc: 0.6381\n",
      "Epoch 28/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6200 - acc: 0.6537\n",
      "Epoch 29/30\n",
      "3976/3976 [==============================] - 0s 9us/sample - loss: 0.6213 - acc: 0.6489\n",
      "Epoch 30/30\n",
      "3976/3976 [==============================] - 0s 7us/sample - loss: 0.6150 - acc: 0.6537\n",
      "attack model no. 1\n",
      "Train on 4104 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4104/4104 [==============================] - 1s 140us/sample - loss: 0.6850 - acc: 0.5482\n",
      "Epoch 2/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6711 - acc: 0.6299\n",
      "Epoch 3/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6628 - acc: 0.6367\n",
      "Epoch 4/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6485 - acc: 0.6650\n",
      "Epoch 5/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6428 - acc: 0.6596\n",
      "Epoch 6/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6261 - acc: 0.6742\n",
      "Epoch 7/30\n",
      "4104/4104 [==============================] - 0s 7us/sample - loss: 0.6259 - acc: 0.6657\n",
      "Epoch 8/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6089 - acc: 0.6835\n",
      "Epoch 9/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6051 - acc: 0.6845\n",
      "Epoch 10/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.6035 - acc: 0.6774\n",
      "Epoch 11/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5929 - acc: 0.6901\n",
      "Epoch 12/30\n",
      "4104/4104 [==============================] - 0s 9us/sample - loss: 0.5925 - acc: 0.6813\n",
      "Epoch 13/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5936 - acc: 0.6808\n",
      "Epoch 14/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5887 - acc: 0.6793\n",
      "Epoch 15/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5906 - acc: 0.6762\n",
      "Epoch 16/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5865 - acc: 0.6798\n",
      "Epoch 17/30\n",
      "4104/4104 [==============================] - 0s 9us/sample - loss: 0.5845 - acc: 0.6808\n",
      "Epoch 18/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5875 - acc: 0.6730\n",
      "Epoch 19/30\n",
      "4104/4104 [==============================] - 0s 9us/sample - loss: 0.5842 - acc: 0.6830\n",
      "Epoch 20/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5815 - acc: 0.6832\n",
      "Epoch 21/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5802 - acc: 0.6823\n",
      "Epoch 22/30\n",
      "4104/4104 [==============================] - 0s 11us/sample - loss: 0.5867 - acc: 0.6742\n",
      "Epoch 23/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5774 - acc: 0.6859\n",
      "Epoch 24/30\n",
      "4104/4104 [==============================] - 0s 9us/sample - loss: 0.5778 - acc: 0.6930\n",
      "Epoch 25/30\n",
      "4104/4104 [==============================] - 0s 12us/sample - loss: 0.5803 - acc: 0.6927\n",
      "Epoch 26/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5790 - acc: 0.6905\n",
      "Epoch 27/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5760 - acc: 0.6842\n",
      "Epoch 28/30\n",
      "4104/4104 [==============================] - 0s 9us/sample - loss: 0.5768 - acc: 0.6837\n",
      "Epoch 29/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5739 - acc: 0.6949\n",
      "Epoch 30/30\n",
      "4104/4104 [==============================] - 0s 8us/sample - loss: 0.5795 - acc: 0.6832\n",
      "attack model no. 2\n",
      "Train on 3800 samples\n",
      "Epoch 1/30\n",
      "3800/3800 [==============================] - 1s 152us/sample - loss: 0.6937 - acc: 0.5142\n",
      "Epoch 2/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.6811 - acc: 0.5708\n",
      "Epoch 3/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6703 - acc: 0.6374\n",
      "Epoch 4/30\n",
      "3800/3800 [==============================] - 0s 6us/sample - loss: 0.6620 - acc: 0.6618\n",
      "Epoch 5/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.6507 - acc: 0.6729\n",
      "Epoch 6/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6395 - acc: 0.6800\n",
      "Epoch 7/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.6292 - acc: 0.6795\n",
      "Epoch 8/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.6248 - acc: 0.6792\n",
      "Epoch 9/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6170 - acc: 0.6837\n",
      "Epoch 10/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6047 - acc: 0.6918\n",
      "Epoch 11/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6030 - acc: 0.6795\n",
      "Epoch 12/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.5869 - acc: 0.7003\n",
      "Epoch 13/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5868 - acc: 0.7024\n",
      "Epoch 14/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5925 - acc: 0.6905\n",
      "Epoch 15/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5955 - acc: 0.6829\n",
      "Epoch 16/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.5891 - acc: 0.6866\n",
      "Epoch 17/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5878 - acc: 0.6805\n",
      "Epoch 18/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5765 - acc: 0.6979\n",
      "Epoch 19/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5777 - acc: 0.6961\n",
      "Epoch 20/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5744 - acc: 0.6929\n",
      "Epoch 21/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5801 - acc: 0.6937\n",
      "Epoch 22/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5799 - acc: 0.6929\n",
      "Epoch 23/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5779 - acc: 0.6976\n",
      "Epoch 24/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5794 - acc: 0.6871\n",
      "Epoch 25/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5747 - acc: 0.6995\n",
      "Epoch 26/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.5827 - acc: 0.6887\n",
      "Epoch 27/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.5740 - acc: 0.6945\n",
      "Epoch 28/30\n",
      "3800/3800 [==============================] - 0s 7us/sample - loss: 0.5730 - acc: 0.6916\n",
      "Epoch 29/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5789 - acc: 0.7000\n",
      "Epoch 30/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5764 - acc: 0.6971\n",
      "attack model no. 3\n",
      "Train on 4032 samples\n",
      "Epoch 1/30\n",
      "4032/4032 [==============================] - 1s 149us/sample - loss: 0.7008 - acc: 0.4898\n",
      "Epoch 2/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6871 - acc: 0.5541\n",
      "Epoch 3/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6783 - acc: 0.6153\n",
      "Epoch 4/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6686 - acc: 0.6560\n",
      "Epoch 5/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6590 - acc: 0.6672\n",
      "Epoch 6/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6502 - acc: 0.6850\n",
      "Epoch 7/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6415 - acc: 0.6905\n",
      "Epoch 8/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6289 - acc: 0.7021\n",
      "Epoch 9/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6172 - acc: 0.7076\n",
      "Epoch 10/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6042 - acc: 0.7128\n",
      "Epoch 11/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5974 - acc: 0.7078\n",
      "Epoch 12/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5886 - acc: 0.7016\n",
      "Epoch 13/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5883 - acc: 0.7011\n",
      "Epoch 14/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5715 - acc: 0.7175\n",
      "Epoch 15/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.5720 - acc: 0.7068\n",
      "Epoch 16/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5691 - acc: 0.7111\n",
      "Epoch 17/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5613 - acc: 0.7202\n",
      "Epoch 18/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5706 - acc: 0.6969\n",
      "Epoch 19/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5573 - acc: 0.7086\n",
      "Epoch 20/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5597 - acc: 0.7135\n",
      "Epoch 21/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5576 - acc: 0.7138\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5637 - acc: 0.7101\n",
      "Epoch 23/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5600 - acc: 0.7016\n",
      "Epoch 24/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5638 - acc: 0.7049\n",
      "Epoch 25/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5558 - acc: 0.7128\n",
      "Epoch 26/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5474 - acc: 0.7143\n",
      "Epoch 27/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5544 - acc: 0.7081\n",
      "Epoch 28/30\n",
      "4032/4032 [==============================] - 0s 13us/sample - loss: 0.5506 - acc: 0.7178\n",
      "Epoch 29/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5493 - acc: 0.7185\n",
      "Epoch 30/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.5615 - acc: 0.6997\n",
      "attack model no. 4\n",
      "Train on 4020 samples\n",
      "Epoch 1/30\n",
      "4020/4020 [==============================] - 1s 147us/sample - loss: 0.6897 - acc: 0.5236\n",
      "Epoch 2/30\n",
      "4020/4020 [==============================] - 0s 6us/sample - loss: 0.6821 - acc: 0.5647\n",
      "Epoch 3/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6752 - acc: 0.5868\n",
      "Epoch 4/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6677 - acc: 0.6164\n",
      "Epoch 5/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6583 - acc: 0.6440\n",
      "Epoch 6/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6519 - acc: 0.6577\n",
      "Epoch 7/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6485 - acc: 0.6525\n",
      "Epoch 8/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6438 - acc: 0.6565\n",
      "Epoch 9/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6408 - acc: 0.6555\n",
      "Epoch 10/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6347 - acc: 0.6659\n",
      "Epoch 11/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6297 - acc: 0.6652\n",
      "Epoch 12/30\n",
      "4020/4020 [==============================] - 0s 11us/sample - loss: 0.6218 - acc: 0.6642\n",
      "Epoch 13/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6194 - acc: 0.6642\n",
      "Epoch 14/30\n",
      "4020/4020 [==============================] - 0s 9us/sample - loss: 0.6178 - acc: 0.6612\n",
      "Epoch 15/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6117 - acc: 0.6659\n",
      "Epoch 16/30\n",
      "4020/4020 [==============================] - 0s 9us/sample - loss: 0.6131 - acc: 0.6687\n",
      "Epoch 17/30\n",
      "4020/4020 [==============================] - 0s 9us/sample - loss: 0.6127 - acc: 0.6679\n",
      "Epoch 18/30\n",
      "4020/4020 [==============================] - 0s 9us/sample - loss: 0.6192 - acc: 0.6537\n",
      "Epoch 19/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6087 - acc: 0.6649\n",
      "Epoch 20/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6142 - acc: 0.6634\n",
      "Epoch 21/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.6062 - acc: 0.6679\n",
      "Epoch 22/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6048 - acc: 0.6776\n",
      "Epoch 23/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6002 - acc: 0.6789\n",
      "Epoch 24/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6039 - acc: 0.6664\n",
      "Epoch 25/30\n",
      "4020/4020 [==============================] - 0s 9us/sample - loss: 0.6004 - acc: 0.6714\n",
      "Epoch 26/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6088 - acc: 0.6659\n",
      "Epoch 27/30\n",
      "4020/4020 [==============================] - 0s 7us/sample - loss: 0.6103 - acc: 0.6624\n",
      "Epoch 28/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6062 - acc: 0.6644\n",
      "Epoch 29/30\n",
      "4020/4020 [==============================] - 0s 8us/sample - loss: 0.6063 - acc: 0.6699\n",
      "Epoch 30/30\n",
      "4020/4020 [==============================] - 0s 9us/sample - loss: 0.6063 - acc: 0.6672\n",
      "attack model no. 5\n",
      "Train on 4096 samples\n",
      "Epoch 1/30\n",
      "4096/4096 [==============================] - 1s 147us/sample - loss: 0.6842 - acc: 0.5745\n",
      "Epoch 2/30\n",
      "4096/4096 [==============================] - 0s 6us/sample - loss: 0.6720 - acc: 0.6362\n",
      "Epoch 3/30\n",
      "4096/4096 [==============================] - 0s 7us/sample - loss: 0.6627 - acc: 0.6614\n",
      "Epoch 4/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.6523 - acc: 0.6675\n",
      "Epoch 5/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.6421 - acc: 0.6697\n",
      "Epoch 6/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.6319 - acc: 0.6831\n",
      "Epoch 7/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.6288 - acc: 0.6716\n",
      "Epoch 8/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.6164 - acc: 0.6726\n",
      "Epoch 9/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.6146 - acc: 0.6785\n",
      "Epoch 10/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5965 - acc: 0.6924\n",
      "Epoch 11/30\n",
      "4096/4096 [==============================] - 0s 10us/sample - loss: 0.6006 - acc: 0.6865\n",
      "Epoch 12/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5959 - acc: 0.6812\n",
      "Epoch 13/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5951 - acc: 0.6833\n",
      "Epoch 14/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5983 - acc: 0.6855\n",
      "Epoch 15/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5933 - acc: 0.6843\n",
      "Epoch 16/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5904 - acc: 0.6865\n",
      "Epoch 17/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5909 - acc: 0.6831\n",
      "Epoch 18/30\n",
      "4096/4096 [==============================] - 0s 11us/sample - loss: 0.6016 - acc: 0.6694\n",
      "Epoch 19/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5857 - acc: 0.6921\n",
      "Epoch 20/30\n",
      "4096/4096 [==============================] - 0s 12us/sample - loss: 0.5800 - acc: 0.6907\n",
      "Epoch 21/30\n",
      "4096/4096 [==============================] - 0s 7us/sample - loss: 0.5804 - acc: 0.6965\n",
      "Epoch 22/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5823 - acc: 0.6897\n",
      "Epoch 23/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5874 - acc: 0.6841\n",
      "Epoch 24/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5814 - acc: 0.6934\n",
      "Epoch 25/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5774 - acc: 0.6958\n",
      "Epoch 26/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5732 - acc: 0.6970\n",
      "Epoch 27/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5793 - acc: 0.6917\n",
      "Epoch 28/30\n",
      "4096/4096 [==============================] - 0s 9us/sample - loss: 0.5782 - acc: 0.6953\n",
      "Epoch 29/30\n",
      "4096/4096 [==============================] - 0s 8us/sample - loss: 0.5741 - acc: 0.7004\n",
      "Epoch 30/30\n",
      "4096/4096 [==============================] - 0s 11us/sample - loss: 0.5846 - acc: 0.6865\n",
      "attack model no. 6\n",
      "Train on 3908 samples\n",
      "Epoch 1/30\n",
      "3908/3908 [==============================] - 1s 155us/sample - loss: 0.6878 - acc: 0.5412\n",
      "Epoch 2/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6805 - acc: 0.5796\n",
      "Epoch 3/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6707 - acc: 0.6134\n",
      "Epoch 4/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6623 - acc: 0.6448\n",
      "Epoch 5/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6541 - acc: 0.6571\n",
      "Epoch 6/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6509 - acc: 0.6482\n",
      "Epoch 7/30\n",
      "3908/3908 [==============================] - 0s 9us/sample - loss: 0.6436 - acc: 0.6581\n",
      "Epoch 8/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6391 - acc: 0.6599\n",
      "Epoch 9/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6416 - acc: 0.6515\n",
      "Epoch 10/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6289 - acc: 0.6722\n",
      "Epoch 11/30\n",
      "3908/3908 [==============================] - 0s 9us/sample - loss: 0.6255 - acc: 0.6697\n",
      "Epoch 12/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6277 - acc: 0.6589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6352 - acc: 0.6546\n",
      "Epoch 14/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6158 - acc: 0.6727\n",
      "Epoch 15/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6153 - acc: 0.6704\n",
      "Epoch 16/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6137 - acc: 0.6684\n",
      "Epoch 17/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6169 - acc: 0.6650\n",
      "Epoch 18/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6073 - acc: 0.6740\n",
      "Epoch 19/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6117 - acc: 0.6663\n",
      "Epoch 20/30\n",
      "3908/3908 [==============================] - 0s 9us/sample - loss: 0.6140 - acc: 0.6638\n",
      "Epoch 21/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6106 - acc: 0.6617\n",
      "Epoch 22/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6074 - acc: 0.6643\n",
      "Epoch 23/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6087 - acc: 0.6622\n",
      "Epoch 24/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6037 - acc: 0.6663\n",
      "Epoch 25/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6035 - acc: 0.6617\n",
      "Epoch 26/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6000 - acc: 0.6704\n",
      "Epoch 27/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6023 - acc: 0.6743\n",
      "Epoch 28/30\n",
      "3908/3908 [==============================] - 0s 8us/sample - loss: 0.6084 - acc: 0.6604\n",
      "Epoch 29/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.5992 - acc: 0.6753\n",
      "Epoch 30/30\n",
      "3908/3908 [==============================] - 0s 7us/sample - loss: 0.6015 - acc: 0.6771\n",
      "attack model no. 7\n",
      "Train on 4120 samples\n",
      "Epoch 1/30\n",
      "4120/4120 [==============================] - 1s 148us/sample - loss: 0.7000 - acc: 0.5070\n",
      "Epoch 2/30\n",
      "4120/4120 [==============================] - 0s 6us/sample - loss: 0.6830 - acc: 0.5602\n",
      "Epoch 3/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.6668 - acc: 0.6255\n",
      "Epoch 4/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.6570 - acc: 0.6444\n",
      "Epoch 5/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.6490 - acc: 0.6519\n",
      "Epoch 6/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.6389 - acc: 0.6626\n",
      "Epoch 7/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.6310 - acc: 0.6600\n",
      "Epoch 8/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.6231 - acc: 0.6650\n",
      "Epoch 9/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.6191 - acc: 0.6617\n",
      "Epoch 10/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.6182 - acc: 0.6689\n",
      "Epoch 11/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.6072 - acc: 0.6711\n",
      "Epoch 12/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.6123 - acc: 0.6626\n",
      "Epoch 13/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.6023 - acc: 0.6743\n",
      "Epoch 14/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.6138 - acc: 0.6617\n",
      "Epoch 15/30\n",
      "4120/4120 [==============================] - 0s 10us/sample - loss: 0.5963 - acc: 0.6714\n",
      "Epoch 16/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.6028 - acc: 0.6728\n",
      "Epoch 17/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.5972 - acc: 0.6813\n",
      "Epoch 18/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.5939 - acc: 0.6799\n",
      "Epoch 19/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.5924 - acc: 0.6791\n",
      "Epoch 20/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.5907 - acc: 0.6857\n",
      "Epoch 21/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.5897 - acc: 0.6823\n",
      "Epoch 22/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.5938 - acc: 0.6837\n",
      "Epoch 23/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.5887 - acc: 0.6876\n",
      "Epoch 24/30\n",
      "4120/4120 [==============================] - 0s 10us/sample - loss: 0.5981 - acc: 0.6740\n",
      "Epoch 25/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.5873 - acc: 0.6847\n",
      "Epoch 26/30\n",
      "4120/4120 [==============================] - 0s 10us/sample - loss: 0.5900 - acc: 0.6891\n",
      "Epoch 27/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.5973 - acc: 0.6786\n",
      "Epoch 28/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.5897 - acc: 0.6847\n",
      "Epoch 29/30\n",
      "4120/4120 [==============================] - 0s 9us/sample - loss: 0.5899 - acc: 0.6850\n",
      "Epoch 30/30\n",
      "4120/4120 [==============================] - 0s 8us/sample - loss: 0.5896 - acc: 0.6833\n",
      "attack model no. 8\n",
      "Train on 3888 samples\n",
      "Epoch 1/30\n",
      "3888/3888 [==============================] - 1s 160us/sample - loss: 0.6902 - acc: 0.5216\n",
      "Epoch 2/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6835 - acc: 0.5584\n",
      "Epoch 3/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6778 - acc: 0.5918\n",
      "Epoch 4/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6685 - acc: 0.6121\n",
      "Epoch 5/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6663 - acc: 0.6083\n",
      "Epoch 6/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6592 - acc: 0.6181\n",
      "Epoch 7/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6593 - acc: 0.6186\n",
      "Epoch 8/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6553 - acc: 0.6211\n",
      "Epoch 9/30\n",
      "3888/3888 [==============================] - 0s 9us/sample - loss: 0.6527 - acc: 0.6255\n",
      "Epoch 10/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6520 - acc: 0.6217\n",
      "Epoch 11/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6499 - acc: 0.6255\n",
      "Epoch 12/30\n",
      "3888/3888 [==============================] - 0s 9us/sample - loss: 0.6448 - acc: 0.6271\n",
      "Epoch 13/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6453 - acc: 0.6350\n",
      "Epoch 14/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6443 - acc: 0.6237\n",
      "Epoch 15/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6449 - acc: 0.6199\n",
      "Epoch 16/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6421 - acc: 0.6178\n",
      "Epoch 17/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6427 - acc: 0.6253\n",
      "Epoch 18/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6395 - acc: 0.6289\n",
      "Epoch 19/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6434 - acc: 0.6145\n",
      "Epoch 20/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6410 - acc: 0.6191\n",
      "Epoch 21/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6413 - acc: 0.6191\n",
      "Epoch 22/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6388 - acc: 0.6229\n",
      "Epoch 23/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6398 - acc: 0.6168\n",
      "Epoch 24/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6375 - acc: 0.6160\n",
      "Epoch 25/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6348 - acc: 0.6296\n",
      "Epoch 26/30\n",
      "3888/3888 [==============================] - ETA: 0s - loss: 0.6326 - acc: 0.624 - 0s 7us/sample - loss: 0.6322 - acc: 0.6340\n",
      "Epoch 27/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6381 - acc: 0.6245\n",
      "Epoch 28/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6337 - acc: 0.6268\n",
      "Epoch 29/30\n",
      "3888/3888 [==============================] - 0s 8us/sample - loss: 0.6285 - acc: 0.6350\n",
      "Epoch 30/30\n",
      "3888/3888 [==============================] - 0s 7us/sample - loss: 0.6327 - acc: 0.6247\n",
      "attack model no. 9\n",
      "Train on 4056 samples\n",
      "Epoch 1/30\n",
      "4056/4056 [==============================] - 1s 156us/sample - loss: 0.7286 - acc: 0.4993\n",
      "Epoch 2/30\n",
      "4056/4056 [==============================] - 0s 7us/sample - loss: 0.6965 - acc: 0.5047\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.6758 - acc: 0.5449\n",
      "Epoch 4/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6601 - acc: 0.6196\n",
      "Epoch 5/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6476 - acc: 0.6640\n",
      "Epoch 6/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6385 - acc: 0.6677\n",
      "Epoch 7/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.6233 - acc: 0.6935\n",
      "Epoch 8/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.6130 - acc: 0.6933\n",
      "Epoch 9/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6055 - acc: 0.6869\n",
      "Epoch 10/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5875 - acc: 0.7083\n",
      "Epoch 11/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5868 - acc: 0.6916\n",
      "Epoch 12/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5786 - acc: 0.6990\n",
      "Epoch 13/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5678 - acc: 0.7056\n",
      "Epoch 14/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5696 - acc: 0.7069\n",
      "Epoch 15/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5704 - acc: 0.6938\n",
      "Epoch 16/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.5660 - acc: 0.7012\n",
      "Epoch 17/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5697 - acc: 0.6955\n",
      "Epoch 18/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5620 - acc: 0.7014\n",
      "Epoch 19/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5556 - acc: 0.7135\n",
      "Epoch 20/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5577 - acc: 0.7115\n",
      "Epoch 21/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.5596 - acc: 0.7046\n",
      "Epoch 22/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.5596 - acc: 0.7076\n",
      "Epoch 23/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.5598 - acc: 0.7059\n",
      "Epoch 24/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.5549 - acc: 0.7128\n",
      "Epoch 25/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5540 - acc: 0.7155\n",
      "Epoch 26/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.5524 - acc: 0.7182\n",
      "Epoch 27/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5539 - acc: 0.7138\n",
      "Epoch 28/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5461 - acc: 0.7177\n",
      "Epoch 29/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5570 - acc: 0.7147\n",
      "Epoch 30/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5494 - acc: 0.7281\n",
      "attack model no. 0\n",
      "Train on 3960 samples\n",
      "Epoch 1/30\n",
      "3960/3960 [==============================] - 1s 168us/sample - loss: 0.6870 - acc: 0.5439\n",
      "Epoch 2/30\n",
      "3960/3960 [==============================] - 0s 6us/sample - loss: 0.6791 - acc: 0.5939\n",
      "Epoch 3/30\n",
      "3960/3960 [==============================] - 0s 7us/sample - loss: 0.6700 - acc: 0.6280\n",
      "Epoch 4/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6660 - acc: 0.6402\n",
      "Epoch 5/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6610 - acc: 0.6449\n",
      "Epoch 6/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6524 - acc: 0.6566\n",
      "Epoch 7/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6569 - acc: 0.6437\n",
      "Epoch 8/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6488 - acc: 0.6551\n",
      "Epoch 9/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6479 - acc: 0.6465\n",
      "Epoch 10/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6402 - acc: 0.6523\n",
      "Epoch 11/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6408 - acc: 0.6439\n",
      "Epoch 12/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6362 - acc: 0.6523\n",
      "Epoch 13/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6372 - acc: 0.6513\n",
      "Epoch 14/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6338 - acc: 0.6485\n",
      "Epoch 15/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6336 - acc: 0.6540\n",
      "Epoch 16/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6222 - acc: 0.6662\n",
      "Epoch 17/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6226 - acc: 0.6513\n",
      "Epoch 18/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6260 - acc: 0.6520\n",
      "Epoch 19/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6200 - acc: 0.6583\n",
      "Epoch 20/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6180 - acc: 0.6540\n",
      "Epoch 21/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6197 - acc: 0.6508\n",
      "Epoch 22/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6193 - acc: 0.6518\n",
      "Epoch 23/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6098 - acc: 0.6639\n",
      "Epoch 24/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6198 - acc: 0.6513\n",
      "Epoch 25/30\n",
      "3960/3960 [==============================] - 0s 8us/sample - loss: 0.6091 - acc: 0.6604\n",
      "Epoch 26/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6162 - acc: 0.6513\n",
      "Epoch 27/30\n",
      "3960/3960 [==============================] - 0s 7us/sample - loss: 0.6103 - acc: 0.6609\n",
      "Epoch 28/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6169 - acc: 0.6548\n",
      "Epoch 29/30\n",
      "3960/3960 [==============================] - 0s 9us/sample - loss: 0.6058 - acc: 0.6699\n",
      "Epoch 30/30\n",
      "3960/3960 [==============================] - 0s 10us/sample - loss: 0.6083 - acc: 0.6551\n",
      "attack model no. 1\n",
      "Train on 4144 samples\n",
      "Epoch 1/30\n",
      "4144/4144 [==============================] - 1s 167us/sample - loss: 0.6841 - acc: 0.5485\n",
      "Epoch 2/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.6672 - acc: 0.6298\n",
      "Epoch 3/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.6559 - acc: 0.6438\n",
      "Epoch 4/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.6424 - acc: 0.6708\n",
      "Epoch 5/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.6332 - acc: 0.6776\n",
      "Epoch 6/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.6251 - acc: 0.6798\n",
      "Epoch 7/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.6171 - acc: 0.6868\n",
      "Epoch 8/30\n",
      "4144/4144 [==============================] - 0s 10us/sample - loss: 0.6122 - acc: 0.6776\n",
      "Epoch 9/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.6091 - acc: 0.6774\n",
      "Epoch 10/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.6054 - acc: 0.6873\n",
      "Epoch 11/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.5949 - acc: 0.6880\n",
      "Epoch 12/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.5990 - acc: 0.6795\n",
      "Epoch 13/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5989 - acc: 0.6827\n",
      "Epoch 14/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5926 - acc: 0.6824\n",
      "Epoch 15/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5921 - acc: 0.6839\n",
      "Epoch 16/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.5890 - acc: 0.6841\n",
      "Epoch 17/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5917 - acc: 0.6721\n",
      "Epoch 18/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5815 - acc: 0.6875\n",
      "Epoch 19/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5777 - acc: 0.6947\n",
      "Epoch 20/30\n",
      "4144/4144 [==============================] - 0s 8us/sample - loss: 0.5757 - acc: 0.6839\n",
      "Epoch 21/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5758 - acc: 0.6887\n",
      "Epoch 22/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5769 - acc: 0.6856\n",
      "Epoch 23/30\n",
      "4144/4144 [==============================] - 0s 10us/sample - loss: 0.5726 - acc: 0.6918\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 0s 10us/sample - loss: 0.5771 - acc: 0.6918\n",
      "Epoch 25/30\n",
      "4144/4144 [==============================] - 0s 13us/sample - loss: 0.5769 - acc: 0.6832\n",
      "Epoch 26/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5690 - acc: 0.6981\n",
      "Epoch 27/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5702 - acc: 0.6938\n",
      "Epoch 28/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5647 - acc: 0.7029\n",
      "Epoch 29/30\n",
      "4144/4144 [==============================] - 0s 10us/sample - loss: 0.5651 - acc: 0.7027\n",
      "Epoch 30/30\n",
      "4144/4144 [==============================] - 0s 9us/sample - loss: 0.5714 - acc: 0.6916\n",
      "attack model no. 2\n",
      "Train on 3800 samples\n",
      "Epoch 1/30\n",
      "3800/3800 [==============================] - 1s 180us/sample - loss: 0.6945 - acc: 0.5045\n",
      "Epoch 2/30\n",
      "3800/3800 [==============================] - 0s 6us/sample - loss: 0.6788 - acc: 0.5611\n",
      "Epoch 3/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6677 - acc: 0.6132\n",
      "Epoch 4/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6589 - acc: 0.6337\n",
      "Epoch 5/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6459 - acc: 0.6671\n",
      "Epoch 6/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6382 - acc: 0.6713\n",
      "Epoch 7/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6295 - acc: 0.6732\n",
      "Epoch 8/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.6199 - acc: 0.6800\n",
      "Epoch 9/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6162 - acc: 0.6779\n",
      "Epoch 10/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.6087 - acc: 0.6816\n",
      "Epoch 11/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.6082 - acc: 0.6811\n",
      "Epoch 12/30\n",
      "3800/3800 [==============================] - 0s 10us/sample - loss: 0.6031 - acc: 0.6866\n",
      "Epoch 13/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.6053 - acc: 0.6782\n",
      "Epoch 14/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5976 - acc: 0.6863\n",
      "Epoch 15/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5932 - acc: 0.6874\n",
      "Epoch 16/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5982 - acc: 0.6803\n",
      "Epoch 17/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5946 - acc: 0.6832\n",
      "Epoch 18/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5865 - acc: 0.6926\n",
      "Epoch 19/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5959 - acc: 0.6853\n",
      "Epoch 20/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5887 - acc: 0.6874\n",
      "Epoch 21/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5883 - acc: 0.6868\n",
      "Epoch 22/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5801 - acc: 0.6966\n",
      "Epoch 23/30\n",
      "3800/3800 [==============================] - 0s 10us/sample - loss: 0.5807 - acc: 0.6942\n",
      "Epoch 24/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5868 - acc: 0.6903\n",
      "Epoch 25/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5799 - acc: 0.6945\n",
      "Epoch 26/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5772 - acc: 0.7000\n",
      "Epoch 27/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5785 - acc: 0.6905\n",
      "Epoch 28/30\n",
      "3800/3800 [==============================] - 0s 8us/sample - loss: 0.5826 - acc: 0.6903\n",
      "Epoch 29/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5793 - acc: 0.6850\n",
      "Epoch 30/30\n",
      "3800/3800 [==============================] - 0s 9us/sample - loss: 0.5778 - acc: 0.6939\n",
      "attack model no. 3\n",
      "Train on 4032 samples\n",
      "Epoch 1/30\n",
      "4032/4032 [==============================] - 1s 170us/sample - loss: 0.6838 - acc: 0.5722\n",
      "Epoch 2/30\n",
      "4032/4032 [==============================] - 0s 7us/sample - loss: 0.6729 - acc: 0.6381\n",
      "Epoch 3/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6636 - acc: 0.6689\n",
      "Epoch 4/30\n",
      "4032/4032 [==============================] - 0s 8us/sample - loss: 0.6526 - acc: 0.6815\n",
      "Epoch 5/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6411 - acc: 0.6882\n",
      "Epoch 6/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6311 - acc: 0.7021\n",
      "Epoch 7/30\n",
      "4032/4032 [==============================] - 0s 10us/sample - loss: 0.6184 - acc: 0.7123\n",
      "Epoch 8/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6073 - acc: 0.7011\n",
      "Epoch 9/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.6003 - acc: 0.7031\n",
      "Epoch 10/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5926 - acc: 0.7073\n",
      "Epoch 11/30\n",
      "4032/4032 [==============================] - 0s 12us/sample - loss: 0.5807 - acc: 0.7130\n",
      "Epoch 12/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5654 - acc: 0.7185\n",
      "Epoch 13/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5713 - acc: 0.7091\n",
      "Epoch 14/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5682 - acc: 0.7113\n",
      "Epoch 15/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5675 - acc: 0.7076\n",
      "Epoch 16/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5599 - acc: 0.7163\n",
      "Epoch 17/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5580 - acc: 0.7153\n",
      "Epoch 18/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5496 - acc: 0.7160\n",
      "Epoch 19/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5572 - acc: 0.7093\n",
      "Epoch 20/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5526 - acc: 0.7153\n",
      "Epoch 21/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5520 - acc: 0.7093\n",
      "Epoch 22/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5522 - acc: 0.7071\n",
      "Epoch 23/30\n",
      "4032/4032 [==============================] - 0s 10us/sample - loss: 0.5599 - acc: 0.6984\n",
      "Epoch 24/30\n",
      "4032/4032 [==============================] - 0s 10us/sample - loss: 0.5532 - acc: 0.7026\n",
      "Epoch 25/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5426 - acc: 0.7135\n",
      "Epoch 26/30\n",
      "4032/4032 [==============================] - 0s 10us/sample - loss: 0.5505 - acc: 0.7076\n",
      "Epoch 27/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5444 - acc: 0.7111\n",
      "Epoch 28/30\n",
      "4032/4032 [==============================] - 0s 10us/sample - loss: 0.5508 - acc: 0.7138\n",
      "Epoch 29/30\n",
      "4032/4032 [==============================] - 0s 10us/sample - loss: 0.5475 - acc: 0.7054\n",
      "Epoch 30/30\n",
      "4032/4032 [==============================] - 0s 9us/sample - loss: 0.5463 - acc: 0.7073\n",
      "attack model no. 4\n",
      "Train on 4028 samples\n",
      "Epoch 1/30\n",
      "4028/4028 [==============================] - 1s 174us/sample - loss: 0.6886 - acc: 0.5459\n",
      "Epoch 2/30\n",
      "4028/4028 [==============================] - 0s 8us/sample - loss: 0.6807 - acc: 0.5983\n",
      "Epoch 3/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6719 - acc: 0.6246\n",
      "Epoch 4/30\n",
      "4028/4028 [==============================] - 0s 8us/sample - loss: 0.6665 - acc: 0.6326\n",
      "Epoch 5/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6581 - acc: 0.6487\n",
      "Epoch 6/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6524 - acc: 0.6554\n",
      "Epoch 7/30\n",
      "4028/4028 [==============================] - 0s 11us/sample - loss: 0.6469 - acc: 0.6569\n",
      "Epoch 8/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6399 - acc: 0.6646\n",
      "Epoch 9/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6370 - acc: 0.6584\n",
      "Epoch 10/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6290 - acc: 0.6661\n",
      "Epoch 11/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6238 - acc: 0.6688\n",
      "Epoch 12/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6257 - acc: 0.6549\n",
      "Epoch 13/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6187 - acc: 0.6686\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4028/4028 [==============================] - 0s 8us/sample - loss: 0.6158 - acc: 0.6693\n",
      "Epoch 15/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6204 - acc: 0.6589\n",
      "Epoch 16/30\n",
      "4028/4028 [==============================] - 0s 13us/sample - loss: 0.6140 - acc: 0.6648\n",
      "Epoch 17/30\n",
      "4028/4028 [==============================] - 0s 8us/sample - loss: 0.6198 - acc: 0.6542\n",
      "Epoch 18/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6120 - acc: 0.6678\n",
      "Epoch 19/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6097 - acc: 0.6730\n",
      "Epoch 20/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6074 - acc: 0.6683\n",
      "Epoch 21/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6041 - acc: 0.6760\n",
      "Epoch 22/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6167 - acc: 0.6529\n",
      "Epoch 23/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6081 - acc: 0.6648\n",
      "Epoch 24/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6089 - acc: 0.6658\n",
      "Epoch 25/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6086 - acc: 0.6616\n",
      "Epoch 26/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6063 - acc: 0.6646\n",
      "Epoch 27/30\n",
      "4028/4028 [==============================] - 0s 10us/sample - loss: 0.6048 - acc: 0.6626\n",
      "Epoch 28/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.5968 - acc: 0.6693\n",
      "Epoch 29/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6055 - acc: 0.6641\n",
      "Epoch 30/30\n",
      "4028/4028 [==============================] - 0s 9us/sample - loss: 0.6036 - acc: 0.6691\n",
      "attack model no. 5\n",
      "Train on 4056 samples\n",
      "Epoch 1/30\n",
      "4056/4056 [==============================] - 1s 176us/sample - loss: 0.6973 - acc: 0.4677\n",
      "Epoch 2/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.6835 - acc: 0.5478\n",
      "Epoch 3/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6710 - acc: 0.6275\n",
      "Epoch 4/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.6612 - acc: 0.6600\n",
      "Epoch 5/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.6512 - acc: 0.6741\n",
      "Epoch 6/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6469 - acc: 0.6578\n",
      "Epoch 7/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6380 - acc: 0.6667\n",
      "Epoch 8/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.6257 - acc: 0.6861\n",
      "Epoch 9/30\n",
      "4056/4056 [==============================] - 0s 8us/sample - loss: 0.6125 - acc: 0.7004\n",
      "Epoch 10/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6152 - acc: 0.6869\n",
      "Epoch 11/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.6045 - acc: 0.6948\n",
      "Epoch 12/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.6064 - acc: 0.6785\n",
      "Epoch 13/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.6000 - acc: 0.6879\n",
      "Epoch 14/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5882 - acc: 0.7051\n",
      "Epoch 15/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5908 - acc: 0.6923\n",
      "Epoch 16/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5870 - acc: 0.6972\n",
      "Epoch 17/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5784 - acc: 0.6958\n",
      "Epoch 18/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5805 - acc: 0.7007\n",
      "Epoch 19/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5813 - acc: 0.6958\n",
      "Epoch 20/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5732 - acc: 0.7014\n",
      "Epoch 21/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5687 - acc: 0.7103\n",
      "Epoch 22/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5740 - acc: 0.7014\n",
      "Epoch 23/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5740 - acc: 0.7009\n",
      "Epoch 24/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5754 - acc: 0.6938\n",
      "Epoch 25/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5673 - acc: 0.7051\n",
      "Epoch 26/30\n",
      "4056/4056 [==============================] - 0s 10us/sample - loss: 0.5719 - acc: 0.6977\n",
      "Epoch 27/30\n",
      "4056/4056 [==============================] - 0s 11us/sample - loss: 0.5665 - acc: 0.7096\n",
      "Epoch 28/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5719 - acc: 0.6995\n",
      "Epoch 29/30\n",
      "4056/4056 [==============================] - 0s 12us/sample - loss: 0.5703 - acc: 0.7059\n",
      "Epoch 30/30\n",
      "4056/4056 [==============================] - 0s 9us/sample - loss: 0.5684 - acc: 0.6960\n",
      "attack model no. 6\n",
      "Train on 3944 samples\n",
      "Epoch 1/30\n",
      "3944/3944 [==============================] - 1s 181us/sample - loss: 0.6957 - acc: 0.4944\n",
      "Epoch 2/30\n",
      "3944/3944 [==============================] - 0s 6us/sample - loss: 0.6846 - acc: 0.5606\n",
      "Epoch 3/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6733 - acc: 0.6009\n",
      "Epoch 4/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6688 - acc: 0.6174\n",
      "Epoch 5/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6573 - acc: 0.6450\n",
      "Epoch 6/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6512 - acc: 0.6587\n",
      "Epoch 7/30\n",
      "3944/3944 [==============================] - 0s 10us/sample - loss: 0.6438 - acc: 0.6661\n",
      "Epoch 8/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6409 - acc: 0.6618\n",
      "Epoch 9/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6336 - acc: 0.6678\n",
      "Epoch 10/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6256 - acc: 0.6757\n",
      "Epoch 11/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6290 - acc: 0.6549\n",
      "Epoch 12/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6271 - acc: 0.6577\n",
      "Epoch 13/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6220 - acc: 0.6651\n",
      "Epoch 14/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6241 - acc: 0.6613\n",
      "Epoch 15/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6214 - acc: 0.6623\n",
      "Epoch 16/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6189 - acc: 0.6635\n",
      "Epoch 17/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6129 - acc: 0.6701\n",
      "Epoch 18/30\n",
      "3944/3944 [==============================] - 0s 10us/sample - loss: 0.6045 - acc: 0.6757\n",
      "Epoch 19/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6047 - acc: 0.6775\n",
      "Epoch 20/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.6064 - acc: 0.6643\n",
      "Epoch 21/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6090 - acc: 0.6722\n",
      "Epoch 22/30\n",
      "3944/3944 [==============================] - 0s 10us/sample - loss: 0.6057 - acc: 0.6706\n",
      "Epoch 23/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.5994 - acc: 0.6815\n",
      "Epoch 24/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.5975 - acc: 0.6709\n",
      "Epoch 25/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.5971 - acc: 0.6777\n",
      "Epoch 26/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.5983 - acc: 0.6752\n",
      "Epoch 27/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.5900 - acc: 0.6818\n",
      "Epoch 28/30\n",
      "3944/3944 [==============================] - 0s 8us/sample - loss: 0.5985 - acc: 0.6732\n",
      "Epoch 29/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.5966 - acc: 0.6760\n",
      "Epoch 30/30\n",
      "3944/3944 [==============================] - 0s 9us/sample - loss: 0.6027 - acc: 0.6694\n",
      "attack model no. 7\n",
      "Train on 4076 samples\n",
      "Epoch 1/30\n",
      "4076/4076 [==============================] - 1s 177us/sample - loss: 0.6950 - acc: 0.5017\n",
      "Epoch 2/30\n",
      "4076/4076 [==============================] - 0s 8us/sample - loss: 0.6849 - acc: 0.5689\n",
      "Epoch 3/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.6751 - acc: 0.6276\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.6666 - acc: 0.6629\n",
      "Epoch 5/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.6584 - acc: 0.6818\n",
      "Epoch 6/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.6473 - acc: 0.6857\n",
      "Epoch 7/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.6368 - acc: 0.6938\n",
      "Epoch 8/30\n",
      "4076/4076 [==============================] - 0s 11us/sample - loss: 0.6238 - acc: 0.6970\n",
      "Epoch 9/30\n",
      "4076/4076 [==============================] - 0s 8us/sample - loss: 0.6152 - acc: 0.6943\n",
      "Epoch 10/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5998 - acc: 0.7041\n",
      "Epoch 11/30\n",
      "4076/4076 [==============================] - 0s 8us/sample - loss: 0.5864 - acc: 0.7093\n",
      "Epoch 12/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5855 - acc: 0.6980\n",
      "Epoch 13/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5807 - acc: 0.7002\n",
      "Epoch 14/30\n",
      "4076/4076 [==============================] - 0s 8us/sample - loss: 0.5774 - acc: 0.6997\n",
      "Epoch 15/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5678 - acc: 0.7019\n",
      "Epoch 16/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5631 - acc: 0.7083\n",
      "Epoch 17/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5704 - acc: 0.6985\n",
      "Epoch 18/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5618 - acc: 0.7063\n",
      "Epoch 19/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5581 - acc: 0.7100\n",
      "Epoch 20/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5636 - acc: 0.7044\n",
      "Epoch 21/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5546 - acc: 0.7117\n",
      "Epoch 22/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5546 - acc: 0.7103\n",
      "Epoch 23/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5518 - acc: 0.7127\n",
      "Epoch 24/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5538 - acc: 0.7132\n",
      "Epoch 25/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5454 - acc: 0.7191\n",
      "Epoch 26/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5559 - acc: 0.7107\n",
      "Epoch 27/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5510 - acc: 0.7154\n",
      "Epoch 28/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5501 - acc: 0.7186\n",
      "Epoch 29/30\n",
      "4076/4076 [==============================] - 0s 10us/sample - loss: 0.5517 - acc: 0.7220\n",
      "Epoch 30/30\n",
      "4076/4076 [==============================] - 0s 9us/sample - loss: 0.5500 - acc: 0.7225\n",
      "attack model no. 8\n",
      "Train on 3836 samples\n",
      "Epoch 1/30\n",
      "3836/3836 [==============================] - 1s 190us/sample - loss: 0.6873 - acc: 0.5498\n",
      "Epoch 2/30\n",
      "3836/3836 [==============================] - 0s 7us/sample - loss: 0.6795 - acc: 0.5912\n",
      "Epoch 3/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6727 - acc: 0.6017\n",
      "Epoch 4/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6665 - acc: 0.6173\n",
      "Epoch 5/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6610 - acc: 0.6204\n",
      "Epoch 6/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6582 - acc: 0.6163\n",
      "Epoch 7/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6526 - acc: 0.6319\n",
      "Epoch 8/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6499 - acc: 0.6277\n",
      "Epoch 9/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6541 - acc: 0.6251\n",
      "Epoch 10/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6474 - acc: 0.6288\n",
      "Epoch 11/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6412 - acc: 0.6358\n",
      "Epoch 12/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6382 - acc: 0.6387\n",
      "Epoch 13/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6397 - acc: 0.6343\n",
      "Epoch 14/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6420 - acc: 0.6257\n",
      "Epoch 15/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6414 - acc: 0.6199\n",
      "Epoch 16/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6333 - acc: 0.6345\n",
      "Epoch 17/30\n",
      "3836/3836 [==============================] - 0s 10us/sample - loss: 0.6320 - acc: 0.6322\n",
      "Epoch 18/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6370 - acc: 0.6298\n",
      "Epoch 19/30\n",
      "3836/3836 [==============================] - 0s 10us/sample - loss: 0.6306 - acc: 0.6382\n",
      "Epoch 20/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6297 - acc: 0.6288\n",
      "Epoch 21/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6257 - acc: 0.6363\n",
      "Epoch 22/30\n",
      "3836/3836 [==============================] - 0s 10us/sample - loss: 0.6247 - acc: 0.6382\n",
      "Epoch 23/30\n",
      "3836/3836 [==============================] - 0s 10us/sample - loss: 0.6295 - acc: 0.6382\n",
      "Epoch 24/30\n",
      "3836/3836 [==============================] - 0s 10us/sample - loss: 0.6209 - acc: 0.6475\n",
      "Epoch 25/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6205 - acc: 0.6389\n",
      "Epoch 26/30\n",
      "3836/3836 [==============================] - 0s 8us/sample - loss: 0.6236 - acc: 0.6468\n",
      "Epoch 27/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6172 - acc: 0.6449\n",
      "Epoch 28/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6236 - acc: 0.6486\n",
      "Epoch 29/30\n",
      "3836/3836 [==============================] - 0s 9us/sample - loss: 0.6261 - acc: 0.6444\n",
      "Epoch 30/30\n",
      "3836/3836 [==============================] - 0s 10us/sample - loss: 0.6228 - acc: 0.6436\n",
      "attack model no. 9\n",
      "Train on 4124 samples\n",
      "Epoch 1/30\n",
      "4124/4124 [==============================] - 1s 181us/sample - loss: 0.6833 - acc: 0.5519\n",
      "Epoch 2/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.6709 - acc: 0.5994\n",
      "Epoch 3/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.6563 - acc: 0.6540\n",
      "Epoch 4/30\n",
      "4124/4124 [==============================] - 0s 10us/sample - loss: 0.6447 - acc: 0.6736\n",
      "Epoch 5/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.6319 - acc: 0.6911\n",
      "Epoch 6/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.6226 - acc: 0.6823\n",
      "Epoch 7/30\n",
      "4124/4124 [==============================] - 0s 10us/sample - loss: 0.6129 - acc: 0.6874\n",
      "Epoch 8/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.6078 - acc: 0.6826\n",
      "Epoch 9/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5967 - acc: 0.6908\n",
      "Epoch 10/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5910 - acc: 0.6894\n",
      "Epoch 11/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5865 - acc: 0.6971\n",
      "Epoch 12/30\n",
      "4124/4124 [==============================] - 0s 11us/sample - loss: 0.5870 - acc: 0.6903\n",
      "Epoch 13/30\n",
      "4124/4124 [==============================] - 0s 11us/sample - loss: 0.5864 - acc: 0.6887\n",
      "Epoch 14/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5889 - acc: 0.6802\n",
      "Epoch 15/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5742 - acc: 0.7025\n",
      "Epoch 16/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5737 - acc: 0.6993\n",
      "Epoch 17/30\n",
      "4124/4124 [==============================] - 0s 8us/sample - loss: 0.5770 - acc: 0.6850\n",
      "Epoch 18/30\n",
      "4124/4124 [==============================] - 0s 10us/sample - loss: 0.5766 - acc: 0.6874\n",
      "Epoch 19/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5785 - acc: 0.6969\n",
      "Epoch 20/30\n",
      "4124/4124 [==============================] - 0s 13us/sample - loss: 0.5677 - acc: 0.6913\n",
      "Epoch 21/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5735 - acc: 0.6877\n",
      "Epoch 22/30\n",
      "4124/4124 [==============================] - 0s 10us/sample - loss: 0.5732 - acc: 0.6872\n",
      "Epoch 23/30\n",
      "4124/4124 [==============================] - 0s 10us/sample - loss: 0.5615 - acc: 0.7032\n",
      "Epoch 24/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5657 - acc: 0.6967\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5636 - acc: 0.6998\n",
      "Epoch 26/30\n",
      "4124/4124 [==============================] - 0s 10us/sample - loss: 0.5692 - acc: 0.6874\n",
      "Epoch 27/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5657 - acc: 0.6920\n",
      "Epoch 28/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5642 - acc: 0.6940\n",
      "Epoch 29/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5589 - acc: 0.7073\n",
      "Epoch 30/30\n",
      "4124/4124 [==============================] - 0s 9us/sample - loss: 0.5563 - acc: 0.7013\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "proportions = [0, 0.5, 0.9, 0.95]\n",
    "ep = 30\n",
    "\n",
    "# List to hold models\n",
    "models = []\n",
    "shadow_models = []\n",
    "train_data = []\n",
    "train_label = []\n",
    "shadow_data = []\n",
    "shadow_label = []\n",
    "\n",
    "for i in range(len(proportions)):\n",
    "    train_data1, train_label1, shadow_data1, shadow_label1 = overlap_datasets(data.train,\n",
    "                                                                         data.labels_train,\n",
    "                                                                         data.shadow,\n",
    "                                                                         data.labels_shadow,\n",
    "                                                                         proportions[i])\n",
    "    \n",
    "    train_data += [train_data1]\n",
    "    train_label += [train_label1]\n",
    "    shadow_data += [shadow_data1]\n",
    "    shadow_label += [shadow_label1]\n",
    "    \n",
    "    models += [hw5_part1_utils.CIFARModel(epochs = ep, batch_size = 2048)]\n",
    "    models[i].init(train_data[i], train_label[i])\n",
    "    \n",
    "    shadow_models += [build_attack_models(\n",
    "                        models[i],\n",
    "                        shadow_data[i],\n",
    "                        shadow_label[i]\n",
    "                    )]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Evaluate Attack Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict each of the labels\n",
    "y_pred_ins = []\n",
    "y_pred_outs= []\n",
    "\n",
    "for i in range(len(proportions)):\n",
    "    target_model = models[i]\n",
    "    y_pred_in = target_model.predict(train_data[i])\n",
    "    y_pred_out = target_model.predict(data.test)\n",
    "    y_pred_ins += [y_pred_in]\n",
    "    y_pred_outs += [y_pred_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate membership of each using the Shadow Attack\n",
    "\n",
    "model_in_preds = []\n",
    "model_out_preds= []\n",
    "\n",
    "for i in range(len(proportions)):\n",
    "    \n",
    "    # Shadow membership attack\n",
    "    model_in_preds += [evaluate_membership(\n",
    "                        shadow_models[i],\n",
    "                        y_pred_in,\n",
    "                        train_label[i]\n",
    "                    )]\n",
    "    model_out_preds += [evaluate_membership(\n",
    "                        shadow_models[i],\n",
    "                        y_pred_out,\n",
    "                        data.labels_test\n",
    "                    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain accuracy of each of the attack methods\n",
    "true_positives = []\n",
    "true_negatives = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(len(proportions)):\n",
    "    true_positives += [(model_in_preds[i] > 0.5).mean()]\n",
    "    true_negatives += [(model_out_preds[i] < 0.5).mean()]\n",
    "    accuracies += [(true_positives[i] + true_negatives[i]) / 2.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Plot of the overfitting measure vs. the accuracies of each of the approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(proportions, accuracies)\n",
    "plt.xlabel('Proportion Data Shared')\n",
    "plt.ylabel('Membership Attack Proportion')\n",
    "plt.title('Membership Attack Accuracy and Data Sharing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36755, 0.36795, 0.36155, 0.5079]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
